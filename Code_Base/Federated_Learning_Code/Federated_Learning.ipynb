{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXW_Zz-4GJvJ",
        "outputId": "bd553774-4eae-46da-ca08-e88e35dec630"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BD585TuQN3o"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Federated Learning Pipeline for CheXpert Dataset\n",
        "=================================================\n",
        "This script implements a comprehensive federated learning pipeline with:\n",
        "- 5 Client nodes with IID distribution\n",
        "- Per-class and multi-class training\n",
        "- Support for ResNet18, DenseNet121, and EfficientNet\n",
        "- Extensive metrics tracking including MAP\n",
        "- Dataset organized in class folders\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from torchvision.datasets import ImageFolder\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import (confusion_matrix, roc_auc_score, f1_score,\n",
        "                           recall_score, roc_curve, average_precision_score,\n",
        "                           precision_recall_curve)\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import copy\n",
        "import random\n",
        "from collections import defaultdict\n",
        "import warnings\n",
        "import gc\n",
        "import psutil\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1Uh70IKTqcE"
      },
      "outputs": [],
      "source": [
        "def setup_gpu():\n",
        "    \"\"\"\n",
        "    Setup GPU for training and print GPU information\n",
        "    \"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"=\"*60)\n",
        "        print(\"GPU INFORMATION\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
        "        print(f\"GPU Count: {torch.cuda.device_count()}\")\n",
        "        print(f\"Current GPU: {torch.cuda.current_device()}\")\n",
        "        print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "\n",
        "        # Clear cache\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        # Set GPU memory fraction\n",
        "        torch.cuda.set_per_process_memory_fraction(0.9)\n",
        "\n",
        "        # Enable cudNN autotuner for better performance\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "        torch.backends.cudnn.enabled = True\n",
        "\n",
        "        # Print initial memory usage\n",
        "        print(f\"Initial GPU Memory Used: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
        "        print(f\"Initial GPU Memory Cached: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        return torch.device(\"cuda\")\n",
        "    else:\n",
        "        print(\"GPU not available, using CPU\")\n",
        "        return torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrAMXqKJTtbF"
      },
      "outputs": [],
      "source": [
        "def print_gpu_memory():\n",
        "    \"\"\"\n",
        "    Print current GPU memory usage\n",
        "    \"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"GPU Memory: Allocated: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB, \"\n",
        "              f\"Cached: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB\")\n",
        "\n",
        "def clear_gpu_memory():\n",
        "    \"\"\"\n",
        "    Clear GPU memory cache\n",
        "    \"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJEapWDmQYLB"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Set random seeds for reproducibility\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vEAPvamQYTw"
      },
      "outputs": [],
      "source": [
        "# Configuration\n",
        "class Config:\n",
        "    # Paths\n",
        "    TRAIN_PATH = \"/content/drive/MyDrive/Colab_Datasets/chexpert_dataset/train\"\n",
        "    TEST_PATH = \"/content/drive/MyDrive/Colab_Datasets/chexpert_dataset/test\"\n",
        "\n",
        "    # Classes\n",
        "    CLASSES = [\"Atelectasis\", \"Cardiomegaly\", \"Consolidation\", \"Edema\", \"Pleural_Effusion\"]\n",
        "    NUM_CLASSES = len(CLASSES)\n",
        "\n",
        "    # Federated Learning Settings\n",
        "    NUM_CLIENTS = 5\n",
        "    NUM_ROUNDS = 10\n",
        "    LOCAL_EPOCHS = 5\n",
        "\n",
        "    # Training Settings\n",
        "    BATCH_SIZE = 32\n",
        "    LEARNING_RATE = 0.001\n",
        "    IMAGE_SIZE = 224\n",
        "    SAMPLES_PER_CLASS = 1000\n",
        "    VAL_SPLIT = 0.2\n",
        "    NUM_WORKERS = 2  # For DataLoader\n",
        "    PIN_MEMORY = True  # For faster GPU transfer\n",
        "\n",
        "    # Mixed Precision Training\n",
        "    USE_AMP = True  # Automatic Mixed Precision\n",
        "    GRADIENT_ACCUMULATION_STEPS = 1  # For larger effective batch size\n",
        "\n",
        "    # # Device\n",
        "    # DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Device - Will be set by setup_gpu()\n",
        "    DEVICE = None\n",
        "\n",
        "    # Model Saves\n",
        "    SAVE_DIR = \"/content/drive/MyDrive/Colab_Datasets/federated_models\"\n",
        "\n",
        "    # Memory Management\n",
        "    CLEAR_CACHE_EVERY_N_ROUNDS = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxqulCsbUUNL",
        "outputId": "a1486fed-eac9-45d3-e2f9-588b22fca0dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "GPU INFORMATION\n",
            "============================================================\n",
            "GPU Available: True\n",
            "GPU Count: 1\n",
            "Current GPU: 0\n",
            "GPU Name: Tesla T4\n",
            "GPU Memory: 15.83 GB\n",
            "Initial GPU Memory Used: 0.00 GB\n",
            "Initial GPU Memory Cached: 0.00 GB\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Initialize GPU\n",
        "Config.DEVICE = setup_gpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rk2YZ9JOQehA"
      },
      "outputs": [],
      "source": [
        "# Custom Dataset Class for folder-based structure\n",
        "class CheXpertFolderDataset(Dataset):\n",
        "    def __init__(self, root_dir, classes, transform=None, samples_per_class=1000):\n",
        "        \"\"\"\n",
        "        Custom dataset for folder-organized CheXpert data\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.classes = classes\n",
        "        self.samples_per_class = samples_per_class\n",
        "        self.class_to_idx = {cls: idx for idx, cls in enumerate(classes)}\n",
        "\n",
        "        self.samples = []\n",
        "        self.targets = []\n",
        "\n",
        "        self._load_samples()\n",
        "\n",
        "    def _load_samples(self):\n",
        "        \"\"\"\n",
        "        Load samples from class folders with retry mechanism for OSError\n",
        "        \"\"\"\n",
        "        import time\n",
        "\n",
        "        max_retries = 5\n",
        "        retry_delay = 5  # seconds\n",
        "\n",
        "        for class_name in self.classes:\n",
        "            class_dir = os.path.join(self.root_dir, class_name)\n",
        "\n",
        "            if not os.path.exists(class_dir):\n",
        "                print(f\"Warning: Directory {class_dir} not found. Skipping class {class_name}\")\n",
        "                continue\n",
        "\n",
        "            image_extensions = ('.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG')\n",
        "            image_files = []\n",
        "\n",
        "            # Add retry logic for os.listdir\n",
        "            for attempt in range(max_retries):\n",
        "                try:\n",
        "                    all_files = os.listdir(class_dir)\n",
        "                    image_files = [os.path.join(class_dir, f) for f in all_files if f.lower().endswith(image_extensions)]\n",
        "                    break # Break if successful\n",
        "                except OSError as e:\n",
        "                    print(f\"OSError reading directory {class_dir}: {e}. Attempt {attempt + 1}/{max_retries}.\")\n",
        "                    if attempt < max_retries - 1:\n",
        "                        time.sleep(retry_delay)\n",
        "                    else:\n",
        "                        print(f\"Failed to read directory {class_dir} after {max_retries} attempts.\")\n",
        "                        # Optionally, raise the exception or skip the class\n",
        "                        # raise e\n",
        "                        image_files = [] # Skip if persistent error\n",
        "                        break\n",
        "\n",
        "\n",
        "            # Limit samples per class\n",
        "            if len(image_files) > self.samples_per_class:\n",
        "                image_files = random.sample(image_files, self.samples_per_class)\n",
        "\n",
        "            # Add samples\n",
        "            if image_files: # Only add samples if image_files is not empty after retries\n",
        "                class_idx = self.class_to_idx[class_name]\n",
        "                for img_path in image_files:\n",
        "                    self.samples.append(img_path)\n",
        "                    self.targets.append(class_idx)\n",
        "\n",
        "\n",
        "        # Shuffle samples\n",
        "        combined = list(zip(self.samples, self.targets))\n",
        "        random.shuffle(combined)\n",
        "        self.samples, self.targets = zip(*combined) if combined else ([], [])\n",
        "\n",
        "        print(f\"Loaded {len(self.samples)} total samples from {self.root_dir}\")\n",
        "        for class_name in self.classes:\n",
        "            count = sum(1 for i, t in enumerate(self.targets) if t == self.class_to_idx[class_name])\n",
        "            print(f\"  {class_name}: {count} samples\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.samples[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = self.targets[idx]\n",
        "\n",
        "        # Create multi-label representation (for compatibility)\n",
        "        multi_label = torch.zeros(len(self.classes))\n",
        "        multi_label[label] = 1.0\n",
        "\n",
        "        return image, label, multi_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pa0L9El3QfFQ"
      },
      "outputs": [],
      "source": [
        "# Model Factory\n",
        "class ModelFactory:\n",
        "    @staticmethod\n",
        "    def create_model(model_name, num_classes, pretrained=True):\n",
        "        \"\"\"\n",
        "        Create model based on name\n",
        "        \"\"\"\n",
        "        if model_name == \"resnet18\":\n",
        "            model = models.resnet18(pretrained=pretrained)\n",
        "            model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "        elif model_name == \"densenet121\":\n",
        "            model = models.densenet121(pretrained=pretrained)\n",
        "            model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
        "        elif model_name == \"efficientnet\":\n",
        "            model = models.efficientnet_b0(pretrained=pretrained)\n",
        "            model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown model: {model_name}\")\n",
        "\n",
        "        # Move model to GPU and enable DataParallel if multiple GPUs\n",
        "        if torch.cuda.device_count() > 1:\n",
        "            print(f\"Using {torch.cuda.device_count()} GPUs for {model_name}\")\n",
        "            model = nn.DataParallel(model)\n",
        "\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBv5Tzw0QfNV"
      },
      "outputs": [],
      "source": [
        "# Metrics Calculator with MAP\n",
        "class MetricsCalculator:\n",
        "    @staticmethod\n",
        "    def calculate_metrics(y_true, y_pred, y_probs, num_classes):\n",
        "        \"\"\"\n",
        "        Calculate comprehensive metrics including MAP\n",
        "        \"\"\"\n",
        "        metrics = {}\n",
        "\n",
        "        # Basic metrics\n",
        "        metrics['accuracy'] = np.mean(y_true == y_pred) * 100\n",
        "\n",
        "        # F1 Score\n",
        "        metrics['f1_score'] = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "        # Recall\n",
        "        metrics['recall'] = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "        # Top-K Accuracy\n",
        "        for k in [1, 5, 10]:\n",
        "            if k <= num_classes:\n",
        "                metrics[f'top_{k}_accuracy'] = MetricsCalculator.top_k_accuracy(y_true, y_probs, k)\n",
        "\n",
        "        # AUC (for multi-class)\n",
        "        if num_classes > 2:\n",
        "            y_true_bin = label_binarize(y_true, classes=range(num_classes))\n",
        "            try:\n",
        "                metrics['auc'] = roc_auc_score(y_true_bin, y_probs, average='weighted', multi_class='ovr')\n",
        "            except:\n",
        "                metrics['auc'] = 0.0\n",
        "        else:\n",
        "            metrics['auc'] = roc_auc_score(y_true, y_probs[:, 1])\n",
        "\n",
        "        # MAP (Mean Average Precision)\n",
        "        metrics['map'] = MetricsCalculator.calculate_map(y_true, y_probs, num_classes)\n",
        "\n",
        "        # Confusion Matrix\n",
        "        metrics['confusion_matrix'] = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_map(y_true, y_probs, num_classes):\n",
        "        \"\"\"\n",
        "        Calculate Mean Average Precision\n",
        "        \"\"\"\n",
        "        if num_classes == 2:\n",
        "            # Binary classification\n",
        "            return average_precision_score(y_true, y_probs[:, 1])\n",
        "        else:\n",
        "            # Multi-class classification\n",
        "            y_true_bin = label_binarize(y_true, classes=range(num_classes))\n",
        "\n",
        "            # Calculate AP for each class\n",
        "            ap_scores = []\n",
        "            for i in range(num_classes):\n",
        "                try:\n",
        "                    ap = average_precision_score(y_true_bin[:, i], y_probs[:, i])\n",
        "                    ap_scores.append(ap)\n",
        "                except:\n",
        "                    ap_scores.append(0.0)\n",
        "\n",
        "            # Return mean of AP scores\n",
        "            return np.mean(ap_scores)\n",
        "\n",
        "    @staticmethod\n",
        "    def top_k_accuracy(y_true, y_probs, k):\n",
        "        \"\"\"\n",
        "        Calculate top-k accuracy\n",
        "        \"\"\"\n",
        "        top_k_preds = np.argsort(y_probs, axis=1)[:, -k:]\n",
        "        correct = 0\n",
        "        for i, true_label in enumerate(y_true):\n",
        "            if true_label in top_k_preds[i]:\n",
        "                correct += 1\n",
        "        return (correct / len(y_true)) * 100\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38H-DlpsQwAX"
      },
      "outputs": [],
      "source": [
        "# Federated Learning Client\n",
        "class FederatedClient:\n",
        "    def __init__(self, client_id, train_data, val_data, model_name, num_classes, device):\n",
        "        self.client_id = client_id\n",
        "        self.train_data = train_data\n",
        "        self.val_data = val_data\n",
        "        self.device = device\n",
        "        self.model_name = model_name\n",
        "        self.model = ModelFactory.create_model(model_name, num_classes).to(device)\n",
        "        # self.criterion = nn.CrossEntropyLoss()\n",
        "        self.criterion = nn.CrossEntropyLoss().to(device)\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=Config.LEARNING_RATE)\n",
        "        self.metrics = defaultdict(list)\n",
        "\n",
        "        # Initialize AMP (Automatic Mixed Precision) for faster training\n",
        "        self.use_amp = Config.USE_AMP and torch.cuda.is_available()\n",
        "        if self.use_amp:\n",
        "            self.scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "\n",
        "    def train_epoch(self):\n",
        "        \"\"\"\n",
        "        Train for one epoch with GPU optimization and mixed precision\n",
        "        \"\"\"\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        train_loader = DataLoader(\n",
        "            self.train_data,\n",
        "            batch_size=Config.BATCH_SIZE,\n",
        "            shuffle=True,\n",
        "            num_workers=Config.NUM_WORKERS,\n",
        "            pin_memory=Config.PIN_MEMORY,\n",
        "            persistent_workers=True if Config.NUM_WORKERS > 0 else False\n",
        "        )\n",
        "\n",
        "        for batch_idx, (images, labels, _) in enumerate(train_loader):\n",
        "            images, labels = images.to(self.device, non_blocking=True), labels.to(self.device, non_blocking=True)\n",
        "\n",
        "            if self.use_amp:\n",
        "                # Mixed precision training\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    outputs = self.model(images)\n",
        "                    loss = self.criterion(outputs, labels)\n",
        "\n",
        "                # Scale loss and backward\n",
        "                self.scaler.scale(loss).backward()\n",
        "\n",
        "                # Gradient accumulation\n",
        "                if (batch_idx + 1) % Config.GRADIENT_ACCUMULATION_STEPS == 0:\n",
        "                    self.scaler.step(self.optimizer)\n",
        "                    self.scaler.update()\n",
        "                    self.optimizer.zero_grad()\n",
        "            else:\n",
        "                # Regular training\n",
        "                outputs = self.model(images)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "\n",
        "                if (batch_idx + 1) % Config.GRADIENT_ACCUMULATION_STEPS == 0:\n",
        "                    self.optimizer.step()\n",
        "                    self.optimizer.zero_grad()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Clear cache periodically to prevent memory overflow\n",
        "            if batch_idx % 10 == 0:\n",
        "                if torch.cuda.is_available():\n",
        "                    torch.cuda.empty_cache()\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        accuracy = 100 * correct / total\n",
        "\n",
        "        return avg_loss, accuracy\n",
        "\n",
        "\n",
        "    def validate(self):\n",
        "        \"\"\"\n",
        "        Validate model with GPU optimization\n",
        "        \"\"\"\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        all_predictions = []\n",
        "        all_labels = []\n",
        "        all_probs = []\n",
        "\n",
        "        val_loader = DataLoader(\n",
        "            self.val_data,\n",
        "            batch_size=Config.BATCH_SIZE,\n",
        "            shuffle=False,\n",
        "            num_workers=Config.NUM_WORKERS,\n",
        "            pin_memory=Config.PIN_MEMORY,\n",
        "            persistent_workers=True if Config.NUM_WORKERS > 0 else False\n",
        "        )\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels, _ in val_loader:\n",
        "                images, labels = images.to(self.device, non_blocking=True), labels.to(self.device, non_blocking=True)\n",
        "\n",
        "                if self.use_amp:\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        outputs = self.model(images)\n",
        "                        loss = self.criterion(outputs, labels)\n",
        "                else:\n",
        "                    outputs = self.model(images)\n",
        "                    loss = self.criterion(outputs, labels)\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "                all_predictions.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "                all_probs.append(torch.softmax(outputs, dim=1).cpu().numpy())\n",
        "\n",
        "        avg_loss = total_loss / len(val_loader) if len(val_loader) > 0 else 0\n",
        "        accuracy = 100 * correct / total if total > 0 else 0\n",
        "        all_probs = np.vstack(all_probs) if all_probs else np.array([])\n",
        "\n",
        "        # Clear GPU cache after validation\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        return avg_loss, accuracy, all_predictions, all_labels, all_probs\n",
        "\n",
        "\n",
        "    def get_model_weights(self):\n",
        "        \"\"\"\n",
        "        Get model weights for aggregation\n",
        "        \"\"\"\n",
        "        # Handle DataParallel wrapper\n",
        "        if isinstance(self.model, nn.DataParallel):\n",
        "            return copy.deepcopy(self.model.module.state_dict())\n",
        "        else:\n",
        "            return copy.deepcopy(self.model.state_dict())\n",
        "\n",
        "\n",
        "    def set_model_weights(self, weights):\n",
        "        \"\"\"\n",
        "        Set model weights from aggregated weights\n",
        "        \"\"\"\n",
        "        # Handle DataParallel wrapper\n",
        "        if isinstance(self.model, nn.DataParallel):\n",
        "            self.model.module.load_state_dict(weights)\n",
        "        else:\n",
        "            self.model.load_state_dict(weights)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGu1tGMuQ51k"
      },
      "outputs": [],
      "source": [
        "# Federated Learning Server\n",
        "class FederatedServer:\n",
        "    def __init__(self, model_name, num_classes, device):\n",
        "        self.global_model = ModelFactory.create_model(model_name, num_classes).to(device)\n",
        "        self.device = device\n",
        "        self.round_metrics = defaultdict(list)\n",
        "\n",
        "\n",
        "    def aggregate_weights(self, client_weights, client_sizes):\n",
        "        \"\"\"\n",
        "        FedAvg aggregation with GPU tensor operations\n",
        "        \"\"\"\n",
        "        total_size = sum(client_sizes)\n",
        "\n",
        "        # Initialize aggregated weights\n",
        "        aggregated_weights = {}\n",
        "\n",
        "        # Get first client's weights as template\n",
        "        for key in client_weights[0].keys():\n",
        "            # Move to GPU for faster aggregation\n",
        "            aggregated_weights[key] = torch.zeros_like(client_weights[0][key]).to(self.device)\n",
        "\n",
        "        # Weighted average using GPU operations\n",
        "        for i, client_weight in enumerate(client_weights):\n",
        "            weight = client_sizes[i] / total_size\n",
        "            for key in client_weight.keys():\n",
        "                aggregated_weights[key] = aggregated_weights[key] + weight * client_weight[key].to(self.device)\n",
        "\n",
        "        # Move back to CPU for storage\n",
        "        for key in aggregated_weights.keys():\n",
        "            aggregated_weights[key] = aggregated_weights[key].cpu()\n",
        "\n",
        "        return aggregated_weights\n",
        "\n",
        "\n",
        "\n",
        "    def update_global_model(self, aggregated_weights):\n",
        "        \"\"\"\n",
        "        Update global model with aggregated weights\n",
        "        \"\"\"\n",
        "        # Handle DataParallel wrapper\n",
        "        if isinstance(self.global_model, nn.DataParallel):\n",
        "            self.global_model.module.load_state_dict(aggregated_weights)\n",
        "        else:\n",
        "            self.global_model.load_state_dict(aggregated_weights)\n",
        "\n",
        "    def get_global_weights(self):\n",
        "        \"\"\"\n",
        "        Get global model weights\n",
        "        \"\"\"\n",
        "        # Handle DataParallel wrapper\n",
        "        if isinstance(self.global_model, nn.DataParallel):\n",
        "            return copy.deepcopy(self.global_model.module.state_dict())\n",
        "        else:\n",
        "            return copy.deepcopy(self.global_model.state_dict())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8u3GhwhQwKq"
      },
      "outputs": [],
      "source": [
        "# Visualization Class\n",
        "class Visualizer:\n",
        "    @staticmethod\n",
        "    def plot_training_curves(metrics_dict, title=\"Training Curves\"):\n",
        "        \"\"\"\n",
        "        Plot training and validation curves including MAP\n",
        "        \"\"\"\n",
        "        fig, axes = plt.subplots(2, 4, figsize=(18, 10))\n",
        "        fig.suptitle(title, fontsize=16)\n",
        "\n",
        "        # Plot Loss\n",
        "        if 'train_loss' in metrics_dict and 'val_loss' in metrics_dict:\n",
        "            axes[0, 0].plot(metrics_dict['train_loss'], label='Train Loss', marker='o')\n",
        "            axes[0, 0].plot(metrics_dict['val_loss'], label='Val Loss', marker='s')\n",
        "            axes[0, 0].set_xlabel('Epoch/Round')\n",
        "            axes[0, 0].set_ylabel('Loss')\n",
        "            axes[0, 0].set_title('Loss Curve')\n",
        "            axes[0, 0].legend()\n",
        "            axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "        # Plot Accuracy\n",
        "        if 'train_acc' in metrics_dict and 'val_acc' in metrics_dict:\n",
        "            axes[0, 1].plot(metrics_dict['train_acc'], label='Train Acc', marker='o')\n",
        "            axes[0, 1].plot(metrics_dict['val_acc'], label='Val Acc', marker='s')\n",
        "            axes[0, 1].set_xlabel('Epoch/Round')\n",
        "            axes[0, 1].set_ylabel('Accuracy (%)')\n",
        "            axes[0, 1].set_title('Accuracy Curve')\n",
        "            axes[0, 1].legend()\n",
        "            axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "        # Plot F1 Score\n",
        "        if 'f1_score' in metrics_dict:\n",
        "            axes[0, 2].plot(metrics_dict['f1_score'], marker='o', color='green')\n",
        "            axes[0, 2].set_xlabel('Epoch/Round')\n",
        "            axes[0, 2].set_ylabel('F1 Score')\n",
        "            axes[0, 2].set_title('F1 Score Curve')\n",
        "            axes[0, 2].grid(True, alpha=0.3)\n",
        "\n",
        "        # Plot MAP\n",
        "        if 'map' in metrics_dict:\n",
        "            axes[0, 3].plot(metrics_dict['map'], marker='o', color='purple')\n",
        "            axes[0, 3].set_xlabel('Epoch/Round')\n",
        "            axes[0, 3].set_ylabel('MAP')\n",
        "            axes[0, 3].set_title('Mean Average Precision Curve')\n",
        "            axes[0, 3].grid(True, alpha=0.3)\n",
        "\n",
        "        # Plot AUC\n",
        "        if 'auc' in metrics_dict:\n",
        "            axes[1, 0].plot(metrics_dict['auc'], marker='o', color='orange')\n",
        "            axes[1, 0].set_xlabel('Epoch/Round')\n",
        "            axes[1, 0].set_ylabel('AUC')\n",
        "            axes[1, 0].set_title('AUC Curve')\n",
        "            axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "        # Plot Top-K Accuracies\n",
        "        top_k_data = []\n",
        "        for k in [1, 5, 10]:\n",
        "            key = f'top_{k}_accuracy'\n",
        "            if key in metrics_dict and metrics_dict[key]:\n",
        "                top_k_data.append((k, metrics_dict[key][-1]))\n",
        "\n",
        "        if top_k_data:\n",
        "            k_values, acc_values = zip(*top_k_data)\n",
        "            bars = axes[1, 1].bar(k_values, acc_values, color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
        "            axes[1, 1].set_xlabel('K')\n",
        "            axes[1, 1].set_ylabel('Accuracy (%)')\n",
        "            axes[1, 1].set_title('Top-K Accuracy')\n",
        "            axes[1, 1].set_xticks(k_values)\n",
        "            axes[1, 1].grid(True, axis='y', alpha=0.3)\n",
        "\n",
        "            # Add value labels on bars\n",
        "            for bar, val in zip(bars, acc_values):\n",
        "                height = bar.get_height()\n",
        "                axes[1, 1].text(bar.get_x() + bar.get_width()/2., height + 1,\n",
        "                              f'{val:.1f}%', ha='center', va='bottom')\n",
        "\n",
        "        # Plot Recall\n",
        "        if 'recall' in metrics_dict:\n",
        "            axes[1, 2].plot(metrics_dict['recall'], marker='o', color='red')\n",
        "            axes[1, 2].set_xlabel('Epoch/Round')\n",
        "            axes[1, 2].set_ylabel('Recall')\n",
        "            axes[1, 2].set_title('Recall Curve')\n",
        "            axes[1, 2].grid(True, alpha=0.3)\n",
        "\n",
        "        # Summary Stats Box\n",
        "        if metrics_dict:\n",
        "            summary_text = \"Final Metrics:\\n\"\n",
        "            if 'val_acc' in metrics_dict and metrics_dict['val_acc']:\n",
        "                summary_text += f\"Acc: {metrics_dict['val_acc'][-1]:.2f}%\\n\"\n",
        "            if 'f1_score' in metrics_dict and metrics_dict['f1_score']:\n",
        "                summary_text += f\"F1: {metrics_dict['f1_score'][-1]:.3f}\\n\"\n",
        "            if 'map' in metrics_dict and metrics_dict['map']:\n",
        "                summary_text += f\"MAP: {metrics_dict['map'][-1]:.3f}\\n\"\n",
        "            if 'auc' in metrics_dict and metrics_dict['auc']:\n",
        "                summary_text += f\"AUC: {metrics_dict['auc'][-1]:.3f}\"\n",
        "\n",
        "            axes[1, 3].text(0.5, 0.5, summary_text, ha='center', va='center',\n",
        "                          fontsize=12, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "            axes[1, 3].set_xlim(0, 1)\n",
        "            axes[1, 3].set_ylim(0, 1)\n",
        "            axes[1, 3].axis('off')\n",
        "            axes[1, 3].set_title('Summary')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_confusion_matrix(cm, classes, title=\"Confusion Matrix\"):\n",
        "        \"\"\"\n",
        "        Plot confusion matrix\n",
        "        \"\"\"\n",
        "        fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "        # Normalize confusion matrix for better visualization\n",
        "        cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "        # Create annotation text with both raw counts and percentages\n",
        "        annot = np.empty_like(cm).astype(str)\n",
        "        for i in range(cm.shape[0]):\n",
        "            for j in range(cm.shape[1]):\n",
        "                annot[i, j] = f'{cm[i, j]}\\n({cm_normalized[i, j]:.1%})'\n",
        "\n",
        "        sns.heatmap(cm, annot=annot, fmt='', cmap='Blues',\n",
        "                    xticklabels=classes, yticklabels=classes, ax=ax,\n",
        "                    cbar_kws={'label': 'Count'})\n",
        "        ax.set_xlabel('Predicted Label', fontsize=12)\n",
        "        ax.set_ylabel('True Label', fontsize=12)\n",
        "        ax.set_title(title, fontsize=14)\n",
        "\n",
        "        return fig\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_per_class_metrics(per_class_metrics, classes):\n",
        "        \"\"\"\n",
        "        Plot per-class performance metrics including MAP\n",
        "        \"\"\"\n",
        "        fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
        "        fig.suptitle('Per-Class Performance Metrics', fontsize=16)\n",
        "\n",
        "        metrics_to_plot = ['accuracy', 'f1_score', 'recall', 'auc', 'map']\n",
        "\n",
        "        for idx, metric in enumerate(metrics_to_plot):\n",
        "            ax = axes[idx // 3, idx % 3]\n",
        "\n",
        "            values = [per_class_metrics[cls].get(metric, 0) for cls in classes]\n",
        "            bars = ax.bar(classes, values)\n",
        "\n",
        "            # Color bars with gradient\n",
        "            colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(classes)))\n",
        "            for bar, color in zip(bars, colors):\n",
        "                bar.set_color(color)\n",
        "\n",
        "            ax.set_xlabel('Class', fontsize=10)\n",
        "            ax.set_ylabel(metric.replace('_', ' ').upper(), fontsize=10)\n",
        "            ax.set_title(f'Per-Class {metric.replace(\"_\", \" \").title()}', fontsize=12)\n",
        "            ax.set_ylim([0, 1.1 if metric != 'accuracy' else 110])\n",
        "            ax.grid(True, axis='y', alpha=0.3)\n",
        "            ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "            # Add value labels on bars\n",
        "            for bar, value in zip(bars, values):\n",
        "                height = bar.get_height()\n",
        "                ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "                       f'{value:.2f}', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "        # Hide the last subplot if we have odd number of metrics\n",
        "        if len(metrics_to_plot) % 3 != 0:\n",
        "            axes[-1, -1].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfJ6sdQWGm03"
      },
      "outputs": [],
      "source": [
        "# Main Federated Learning Pipeline\n",
        "class FederatedLearningPipeline:\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.device = config.DEVICE\n",
        "        self.results = defaultdict(lambda: defaultdict(dict))\n",
        "\n",
        "        # Create save directory\n",
        "        os.makedirs(config.SAVE_DIR, exist_ok=True)\n",
        "\n",
        "        # Data transformations\n",
        "        self.train_transform = transforms.Compose([\n",
        "            transforms.Resize((config.IMAGE_SIZE, config.IMAGE_SIZE)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomRotation(10),\n",
        "            transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        self.val_transform = transforms.Compose([\n",
        "            transforms.Resize((config.IMAGE_SIZE, config.IMAGE_SIZE)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"\n",
        "        Load and prepare dataset from folder structure\n",
        "        \"\"\"\n",
        "        print(\"Loading CheXpert dataset from folders...\")\n",
        "\n",
        "        # Load train dataset\n",
        "        self.train_dataset = CheXpertFolderDataset(\n",
        "            root_dir=self.config.TRAIN_PATH,\n",
        "            classes=self.config.CLASSES,\n",
        "            transform=self.train_transform,\n",
        "            samples_per_class=self.config.SAMPLES_PER_CLASS\n",
        "        )\n",
        "\n",
        "        # Load test dataset\n",
        "        self.test_dataset = CheXpertFolderDataset(\n",
        "            root_dir=self.config.TEST_PATH,\n",
        "            classes=self.config.CLASSES,\n",
        "            transform=self.val_transform,\n",
        "            samples_per_class=self.config.SAMPLES_PER_CLASS // 5  # Smaller test set\n",
        "        )\n",
        "\n",
        "        print(f\"\\nDataset Summary:\")\n",
        "        print(f\"Train dataset size: {len(self.train_dataset)}\")\n",
        "        print(f\"Test dataset size: {len(self.test_dataset)}\")\n",
        "\n",
        "    def create_federated_datasets(self, dataset, num_clients):\n",
        "        \"\"\"\n",
        "        Split dataset into federated clients (IID)\n",
        "        \"\"\"\n",
        "        total_size = len(dataset)\n",
        "        indices = list(range(total_size))\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "        # Split indices for each client\n",
        "        split_size = total_size // num_clients\n",
        "        client_indices = []\n",
        "\n",
        "        for i in range(num_clients):\n",
        "            start_idx = i * split_size\n",
        "            end_idx = start_idx + split_size if i < num_clients - 1 else total_size\n",
        "            client_indices.append(indices[start_idx:end_idx])\n",
        "\n",
        "        # Create subsets for each client\n",
        "        client_datasets = []\n",
        "        for idx_list in client_indices:\n",
        "            client_datasets.append(Subset(dataset, idx_list))\n",
        "\n",
        "        return client_datasets\n",
        "\n",
        "    def split_train_val(self, dataset, val_split=0.2):\n",
        "        \"\"\"\n",
        "        Split dataset into train and validation\n",
        "        \"\"\"\n",
        "        total_size = len(dataset)\n",
        "        val_size = int(total_size * val_split)\n",
        "        train_size = total_size - val_size\n",
        "\n",
        "        indices = list(range(total_size))\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "        train_indices = indices[:train_size]\n",
        "        val_indices = indices[train_size:]\n",
        "\n",
        "        train_subset = Subset(dataset, train_indices)\n",
        "        val_subset = Subset(dataset, val_indices)\n",
        "\n",
        "        return train_subset, val_subset\n",
        "\n",
        "    def create_binary_dataset(self, dataset, target_class_idx):\n",
        "        \"\"\"\n",
        "        Create binary dataset for a specific class (one-vs-all)\n",
        "        \"\"\"\n",
        "        binary_samples = []\n",
        "        binary_targets = []\n",
        "\n",
        "        for i in range(len(dataset)):\n",
        "            _, label, _ = dataset[i]\n",
        "            if isinstance(label, torch.Tensor):\n",
        "                label = label.item()\n",
        "\n",
        "            # Include samples from target class as positive (1)\n",
        "            if label == target_class_idx:\n",
        "                binary_samples.append(i)\n",
        "                binary_targets.append(1)\n",
        "            # Include samples from other classes as negative (0)\n",
        "            else:\n",
        "                binary_samples.append(i)\n",
        "                binary_targets.append(0)\n",
        "\n",
        "        # Balance the dataset\n",
        "        pos_indices = [i for i, t in enumerate(binary_targets) if t == 1]\n",
        "        neg_indices = [i for i, t in enumerate(binary_targets) if t == 0]\n",
        "\n",
        "        min_samples = min(len(pos_indices), len(neg_indices))\n",
        "        balanced_indices = pos_indices[:min_samples] + neg_indices[:min_samples]\n",
        "        np.random.shuffle(balanced_indices)\n",
        "\n",
        "        # Create subset with balanced samples\n",
        "        final_indices = [binary_samples[i] for i in balanced_indices]\n",
        "\n",
        "        # Create a wrapper to return binary labels\n",
        "        class BinaryWrapper(Dataset):\n",
        "            def __init__(self, dataset, indices, target_class):\n",
        "                self.dataset = dataset\n",
        "                self.indices = indices\n",
        "                self.target_class = target_class\n",
        "\n",
        "            def __len__(self):\n",
        "                return len(self.indices)\n",
        "\n",
        "            def __getitem__(self, idx):\n",
        "                real_idx = self.indices[idx]\n",
        "                image, label, multi = self.dataset[real_idx]\n",
        "                # Convert to binary: 1 if target class, 0 otherwise\n",
        "                binary_label = 1 if label == self.target_class else 0\n",
        "                return image, binary_label, multi\n",
        "\n",
        "        return BinaryWrapper(dataset, final_indices, target_class_idx)\n",
        "\n",
        "\n",
        "    def train_per_class_federated(self, model_name, class_idx, class_name):\n",
        "        \"\"\"\n",
        "        Train federated learning for a single class (binary classification)\n",
        "        \"\"\"\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"Training {model_name} for class: {class_name}\")\n",
        "        print(f\"{'='*50}\")\n",
        "\n",
        "        # Create binary dataset for this class\n",
        "        binary_train_dataset = self.create_binary_dataset(self.train_dataset, class_idx)\n",
        "        binary_test_dataset = self.create_binary_dataset(self.test_dataset, class_idx)\n",
        "\n",
        "        # Check if there are enough samples for training\n",
        "        if len(binary_train_dataset) == 0:\n",
        "            print(f\"Skipping training for {class_name}: Not enough samples.\")\n",
        "            # Store empty metrics to avoid errors later\n",
        "            self.results[model_name][class_name] = {\n",
        "                'training_metrics': {},\n",
        "                'test_metrics': {},\n",
        "                'confusion_matrix': np.zeros((2, 2))\n",
        "            }\n",
        "            return {}, {}\n",
        "\n",
        "\n",
        "        # Create federated datasets\n",
        "        client_datasets = self.create_federated_datasets(binary_train_dataset, self.config.NUM_CLIENTS)\n",
        "\n",
        "        # Initialize server and clients\n",
        "        server = FederatedServer(model_name, 2, self.device)  # Binary classification\n",
        "        clients = []\n",
        "\n",
        "        for i, client_data in enumerate(client_datasets):\n",
        "            train_data, val_data = self.split_train_val(client_data, self.config.VAL_SPLIT)\n",
        "            client = FederatedClient(i, train_data, val_data, model_name, 2, self.device)\n",
        "            clients.append(client)\n",
        "\n",
        "        # Training metrics storage\n",
        "        metrics = {\n",
        "            'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [],\n",
        "            'f1_score': [], 'auc': [], 'recall': [], 'map': [],\n",
        "            'top_1_accuracy': [], 'top_5_accuracy': []\n",
        "        }\n",
        "\n",
        "        # Federated training rounds\n",
        "        for round_num in range(self.config.NUM_ROUNDS):\n",
        "            print(f\"\\nRound {round_num + 1}/{self.config.NUM_ROUNDS}\")\n",
        "\n",
        "            # Distribute global weights to clients\n",
        "            global_weights = server.get_global_weights()\n",
        "            for client in clients:\n",
        "                client.set_model_weights(global_weights)\n",
        "\n",
        "            # Local training\n",
        "            client_weights = []\n",
        "            client_sizes = []\n",
        "            round_train_loss = []\n",
        "            round_train_acc = []\n",
        "\n",
        "            for client in clients:\n",
        "                # Train for local epochs\n",
        "                for epoch in range(self.config.LOCAL_EPOCHS):\n",
        "                    loss, acc = client.train_epoch()\n",
        "                    round_train_loss.append(loss)\n",
        "                    round_train_acc.append(acc)\n",
        "\n",
        "                # Get client weights\n",
        "                client_weights.append(client.get_model_weights())\n",
        "                client_sizes.append(len(client.train_data))\n",
        "\n",
        "            # Aggregate weights\n",
        "            aggregated_weights = server.aggregate_weights(client_weights, client_sizes)\n",
        "            server.update_global_model(aggregated_weights)\n",
        "\n",
        "            # Validation on aggregated model\n",
        "            val_losses = []\n",
        "            val_accs = []\n",
        "            all_preds = []\n",
        "            all_labels = []\n",
        "            all_probs = []\n",
        "\n",
        "            for client in clients:\n",
        "                client.set_model_weights(aggregated_weights)\n",
        "                val_loss, val_acc, preds, labels, probs = client.validate()\n",
        "                val_losses.append(val_loss)\n",
        "                val_accs.append(val_acc)\n",
        "                if len(preds) > 0:\n",
        "                    all_preds.extend(preds)\n",
        "                    all_labels.extend(labels)\n",
        "                    all_probs.append(probs)\n",
        "\n",
        "            # Calculate metrics if we have predictions\n",
        "            if all_preds:\n",
        "                all_probs = np.vstack(all_probs)\n",
        "                round_metrics = MetricsCalculator.calculate_metrics(\n",
        "                    np.array(all_labels), np.array(all_preds), all_probs, 2\n",
        "                )\n",
        "\n",
        "                # Store metrics\n",
        "                metrics['train_loss'].append(np.mean(round_train_loss))\n",
        "                metrics['train_acc'].append(np.mean(round_train_acc))\n",
        "                metrics['val_loss'].append(np.mean(val_losses))\n",
        "                metrics['val_acc'].append(np.mean(val_accs))\n",
        "                metrics['f1_score'].append(round_metrics['f1_score'])\n",
        "                metrics['auc'].append(round_metrics['auc'])\n",
        "                metrics['recall'].append(round_metrics['recall'])\n",
        "                metrics['map'].append(round_metrics['map'])\n",
        "                metrics['top_1_accuracy'].append(round_metrics['top_1_accuracy'])\n",
        "\n",
        "                print(f\"Avg Train Loss: {metrics['train_loss'][-1]:.4f}, \"\n",
        "                      f\"Avg Train Acc: {metrics['train_acc'][-1]:.2f}%\")\n",
        "                print(f\"Avg Val Loss: {metrics['val_loss'][-1]:.4f}, \"\n",
        "                      f\"Avg Val Acc: {metrics['val_acc'][-1]:.2f}%\")\n",
        "                print(f\"F1 Score: {metrics['f1_score'][-1]:.4f}, \"\n",
        "                      f\"AUC: {metrics['auc'][-1]:.4f}, \"\n",
        "                      f\"MAP: {metrics['map'][-1]:.4f}\")\n",
        "\n",
        "        # Test evaluation\n",
        "        test_metrics = self.evaluate_on_test(server.global_model, binary_test_dataset, 2)\n",
        "\n",
        "        # Save model\n",
        "        model_path = os.path.join(self.config.SAVE_DIR, f\"{model_name}_{class_name}_model.pth\")\n",
        "        torch.save(server.global_model.state_dict(), model_path)\n",
        "        print(f\"Model saved to {model_path}\")\n",
        "\n",
        "        # Store results\n",
        "        self.results[model_name][class_name] = {\n",
        "            'training_metrics': metrics,\n",
        "            'test_metrics': test_metrics,\n",
        "            'confusion_matrix': test_metrics['confusion_matrix']\n",
        "        }\n",
        "\n",
        "        return metrics, test_metrics\n",
        "\n",
        "    def train_multiclass_federated(self, model_name):\n",
        "        \"\"\"\n",
        "        Train federated learning for multi-class classification\n",
        "        \"\"\"\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"Training {model_name} for Multi-Class Classification\")\n",
        "        print(f\"{'='*50}\")\n",
        "\n",
        "        # Create federated datasets\n",
        "        client_datasets = self.create_federated_datasets(self.train_dataset, self.config.NUM_CLIENTS)\n",
        "\n",
        "        # Initialize server and clients\n",
        "        server = FederatedServer(model_name, self.config.NUM_CLASSES, self.device)\n",
        "        clients = []\n",
        "\n",
        "        for i, client_data in enumerate(client_datasets):\n",
        "            train_data, val_data = self.split_train_val(client_data, self.config.VAL_SPLIT)\n",
        "            client = FederatedClient(i, train_data, val_data, model_name,\n",
        "                                   self.config.NUM_CLASSES, self.device)\n",
        "            clients.append(client)\n",
        "\n",
        "        # Training metrics storage\n",
        "        metrics = {\n",
        "            'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [],\n",
        "            'f1_score': [], 'auc': [], 'recall': [], 'map': [],\n",
        "            'top_1_accuracy': [], 'top_5_accuracy': [], 'top_10_accuracy': []\n",
        "        }\n",
        "\n",
        "        # Federated training rounds\n",
        "        for round_num in range(self.config.NUM_ROUNDS):\n",
        "            print(f\"\\nRound {round_num + 1}/{self.config.NUM_ROUNDS}\")\n",
        "\n",
        "            # Distribute global weights to clients\n",
        "            global_weights = server.get_global_weights()\n",
        "            for client in clients:\n",
        "                client.set_model_weights(global_weights)\n",
        "\n",
        "            # Local training\n",
        "            client_weights = []\n",
        "            client_sizes = []\n",
        "            round_train_loss = []\n",
        "            round_train_acc = []\n",
        "\n",
        "            for client in clients:\n",
        "                # Train for local epochs\n",
        "                for epoch in range(self.config.LOCAL_EPOCHS):\n",
        "                    loss, acc = client.train_epoch()\n",
        "                    round_train_loss.append(loss)\n",
        "                    round_train_acc.append(acc)\n",
        "\n",
        "                # Get client weights\n",
        "                client_weights.append(client.get_model_weights())\n",
        "                client_sizes.append(len(client.train_data))\n",
        "\n",
        "            # Aggregate weights\n",
        "            aggregated_weights = server.aggregate_weights(client_weights, client_sizes)\n",
        "            server.update_global_model(aggregated_weights)\n",
        "\n",
        "            # Validation on aggregated model\n",
        "            val_losses = []\n",
        "            val_accs = []\n",
        "            all_preds = []\n",
        "            all_labels = []\n",
        "            all_probs = []\n",
        "\n",
        "            for client in clients:\n",
        "                client.set_model_weights(aggregated_weights)\n",
        "                val_loss, val_acc, preds, labels, probs = client.validate()\n",
        "                val_losses.append(val_loss)\n",
        "                val_accs.append(val_acc)\n",
        "                if len(preds) > 0:\n",
        "                    all_preds.extend(preds)\n",
        "                    all_labels.extend(labels)\n",
        "                    all_probs.append(probs)\n",
        "\n",
        "            # Calculate metrics if we have predictions\n",
        "            if all_preds:\n",
        "                all_probs = np.vstack(all_probs)\n",
        "                round_metrics = MetricsCalculator.calculate_metrics(\n",
        "                    np.array(all_labels), np.array(all_preds), all_probs, self.config.NUM_CLASSES\n",
        "                )\n",
        "\n",
        "                # Store metrics\n",
        "                metrics['train_loss'].append(np.mean(round_train_loss))\n",
        "                metrics['train_acc'].append(np.mean(round_train_acc))\n",
        "                metrics['val_loss'].append(np.mean(val_losses))\n",
        "                metrics['val_acc'].append(np.mean(val_accs))\n",
        "                metrics['f1_score'].append(round_metrics['f1_score'])\n",
        "                metrics['auc'].append(round_metrics['auc'])\n",
        "                metrics['recall'].append(round_metrics['recall'])\n",
        "                metrics['map'].append(round_metrics['map'])\n",
        "                metrics['top_1_accuracy'].append(round_metrics['top_1_accuracy'])\n",
        "                metrics['top_5_accuracy'].append(round_metrics.get('top_5_accuracy', 0))\n",
        "\n",
        "                print(f\"Avg Train Loss: {metrics['train_loss'][-1]:.4f}, \"\n",
        "                      f\"Avg Train Acc: {metrics['train_acc'][-1]:.2f}%\")\n",
        "                print(f\"Avg Val Loss: {metrics['val_loss'][-1]:.4f}, \"\n",
        "                      f\"Avg Val Acc: {metrics['val_acc'][-1]:.2f}%\")\n",
        "                print(f\"F1 Score: {metrics['f1_score'][-1]:.4f}, \"\n",
        "                      f\"AUC: {metrics['auc'][-1]:.4f}, \"\n",
        "                      f\"MAP: {metrics['map'][-1]:.4f}\")\n",
        "\n",
        "        # Test evaluation\n",
        "        test_metrics = self.evaluate_on_test(server.global_model, self.test_dataset,\n",
        "                                            self.config.NUM_CLASSES)\n",
        "\n",
        "        # Save model\n",
        "        model_path = os.path.join(self.config.SAVE_DIR, f\"{model_name}_multiclass_model.pth\")\n",
        "        torch.save(server.global_model.state_dict(), model_path)\n",
        "        print(f\"Model saved to {model_path}\")\n",
        "\n",
        "        # Store results\n",
        "        self.results[model_name]['multiclass'] = {\n",
        "            'training_metrics': metrics,\n",
        "            'test_metrics': test_metrics,\n",
        "            'confusion_matrix': test_metrics['confusion_matrix']\n",
        "        }\n",
        "\n",
        "        return metrics, test_metrics\n",
        "\n",
        "    def evaluate_on_test(self, model, test_dataset, num_classes):\n",
        "        \"\"\"\n",
        "        Evaluate model on test dataset\n",
        "        \"\"\"\n",
        "        model.eval()\n",
        "        test_loader = DataLoader(test_dataset, batch_size=self.config.BATCH_SIZE, shuffle=False)\n",
        "\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        all_probs = []\n",
        "        total_loss = 0\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels, _ in test_loader:\n",
        "                images, labels = images.to(self.device), labels.to(self.device)\n",
        "\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "                all_preds.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "                all_probs.append(torch.softmax(outputs, dim=1).cpu().numpy())\n",
        "\n",
        "        if all_probs:\n",
        "            all_probs = np.vstack(all_probs)\n",
        "\n",
        "            # Calculate comprehensive metrics\n",
        "            test_metrics = MetricsCalculator.calculate_metrics(\n",
        "                np.array(all_labels), np.array(all_preds), all_probs, num_classes\n",
        "            )\n",
        "            test_metrics['test_loss'] = total_loss / len(test_loader)\n",
        "\n",
        "            print(f\"\\nTest Results:\")\n",
        "            print(f\"Test Loss: {test_metrics['test_loss']:.4f}\")\n",
        "            print(f\"Test Accuracy: {test_metrics['accuracy']:.2f}%\")\n",
        "            print(f\"Test F1 Score: {test_metrics['f1_score']:.4f}\")\n",
        "            print(f\"Test AUC: {test_metrics['auc']:.4f}\")\n",
        "            print(f\"Test MAP: {test_metrics['map']:.4f}\")\n",
        "            print(f\"Test Recall: {test_metrics['recall']:.4f}\")\n",
        "        else:\n",
        "            test_metrics = {\n",
        "                'test_loss': 0, 'accuracy': 0, 'f1_score': 0,\n",
        "                'auc': 0, 'map': 0, 'recall': 0,\n",
        "                'confusion_matrix': np.zeros((num_classes, num_classes))\n",
        "            }\n",
        "\n",
        "        return test_metrics\n",
        "\n",
        "\n",
        "    def visualize_results(self, model_name):\n",
        "        \"\"\"\n",
        "        Create comprehensive visualizations for results\n",
        "        \"\"\"\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"Generating Visualizations for {model_name}\")\n",
        "        print(f\"{'='*50}\")\n",
        "\n",
        "        # Create figure directory\n",
        "        fig_dir = os.path.join(self.config.SAVE_DIR, f\"{model_name}_figures\")\n",
        "        os.makedirs(fig_dir, exist_ok=True)\n",
        "\n",
        "        # 1. Per-Class Training Curves\n",
        "        for class_name in self.config.CLASSES:\n",
        "            if class_name in self.results[model_name] and self.results[model_name][class_name].get('training_metrics'):\n",
        "                metrics = self.results[model_name][class_name]['training_metrics']\n",
        "                fig = Visualizer.plot_training_curves(\n",
        "                    metrics, f\"{model_name} - {class_name} Training Curves\"\n",
        "                )\n",
        "                fig.savefig(os.path.join(fig_dir, f\"{class_name}_training_curves.png\"),\n",
        "                           dpi=100, bbox_inches='tight')\n",
        "                plt.close(fig)\n",
        "\n",
        "                # Confusion Matrix for class\n",
        "                cm = self.results[model_name][class_name]['confusion_matrix']\n",
        "                fig = Visualizer.plot_confusion_matrix(\n",
        "                    cm, ['Negative', 'Positive'],\n",
        "                    f\"{model_name} - {class_name} Confusion Matrix\"\n",
        "                )\n",
        "                fig.savefig(os.path.join(fig_dir, f\"{class_name}_confusion_matrix.png\"),\n",
        "                           dpi=100, bbox_inches='tight')\n",
        "                plt.close(fig)\n",
        "\n",
        "        # 2. Multi-Class Results\n",
        "        if 'multiclass' in self.results[model_name] and self.results[model_name]['multiclass'].get('training_metrics'):\n",
        "            metrics = self.results[model_name]['multiclass']['training_metrics']\n",
        "            fig = Visualizer.plot_training_curves(\n",
        "                metrics, f\"{model_name} - Multi-Class Training Curves\"\n",
        "            )\n",
        "            fig.savefig(os.path.join(fig_dir, \"multiclass_training_curves.png\"),\n",
        "                       dpi=100, bbox_inches='tight')\n",
        "            plt.close(fig)\n",
        "\n",
        "            # Multi-class Confusion Matrix\n",
        "            cm = self.results[model_name]['multiclass']['confusion_matrix']\n",
        "            fig = Visualizer.plot_confusion_matrix(\n",
        "                cm, self.config.CLASSES,\n",
        "                f\"{model_name} - Multi-Class Confusion Matrix\"\n",
        "            )\n",
        "            fig.savefig(os.path.join(fig_dir, \"multiclass_confusion_matrix.png\"),\n",
        "                       dpi=100, bbox_inches='tight')\n",
        "            plt.close(fig)\n",
        "\n",
        "        # 3. Comparative Per-Class Metrics\n",
        "        per_class_metrics = {}\n",
        "        for class_name in self.config.CLASSES:\n",
        "            if class_name in self.results[model_name] and self.results[model_name][class_name].get('test_metrics'):\n",
        "                test_metrics = self.results[model_name][class_name]['test_metrics']\n",
        "                per_class_metrics[class_name] = test_metrics\n",
        "\n",
        "        if per_class_metrics:\n",
        "            # Filter out classes that were skipped due to no samples\n",
        "            classes_with_metrics = [cls for cls in self.config.CLASSES if cls in per_class_metrics]\n",
        "            fig = Visualizer.plot_per_class_metrics(per_class_metrics, classes_with_metrics)\n",
        "            fig.savefig(os.path.join(fig_dir, \"per_class_comparison.png\"),\n",
        "                       dpi=100, bbox_inches='tight')\n",
        "            plt.close(fig)\n",
        "\n",
        "        print(f\"Visualizations saved to {fig_dir}\")\n",
        "\n",
        "    def generate_summary_report(self):\n",
        "        \"\"\"\n",
        "        Generate comprehensive summary report with all metrics\n",
        "        \"\"\"\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(\"FEDERATED LEARNING SUMMARY REPORT\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        summary = []\n",
        "        summary.append(\"=\"*60)\n",
        "        summary.append(\"FEDERATED LEARNING EXPERIMENT RESULTS\")\n",
        "        summary.append(\"=\"*60)\n",
        "        summary.append(f\"\\nExperiment Configuration:\")\n",
        "        summary.append(f\"  - Number of Clients: {self.config.NUM_CLIENTS}\")\n",
        "        summary.append(f\"  - Number of Rounds: {self.config.NUM_ROUNDS}\")\n",
        "        summary.append(f\"  - Local Epochs: {self.config.LOCAL_EPOCHS}\")\n",
        "        summary.append(f\"  - Batch Size: {self.config.BATCH_SIZE}\")\n",
        "        summary.append(f\"  - Learning Rate: {self.config.LEARNING_RATE}\")\n",
        "        summary.append(f\"  - Samples per Class: {self.config.SAMPLES_PER_CLASS}\")\n",
        "        summary.append(f\"  - Device: {self.config.DEVICE}\")\n",
        "\n",
        "        # Model comparison table\n",
        "        summary.append(\"\\n\" + \"=\"*60)\n",
        "        summary.append(\"MODEL PERFORMANCE COMPARISON\")\n",
        "        summary.append(\"=\"*60)\n",
        "\n",
        "        for model_name in self.results.keys():\n",
        "            summary.append(f\"\\n### Model: {model_name.upper()} ###\\n\")\n",
        "\n",
        "            # Per-Class Results\n",
        "            summary.append(\"Per-Class Binary Classification Results:\")\n",
        "            summary.append(\"-\" * 40)\n",
        "\n",
        "            for class_name in self.config.CLASSES:\n",
        "                if class_name in self.results[model_name] and self.results[model_name][class_name].get('test_metrics'):\n",
        "                    test_metrics = self.results[model_name][class_name]['test_metrics']\n",
        "                    summary.append(f\"\\n  {class_name}:\")\n",
        "                    summary.append(f\"    - Accuracy:  {test_metrics['accuracy']:.2f}%\")\n",
        "                    summary.append(f\"    - F1 Score:  {test_metrics['f1_score']:.4f}\")\n",
        "                    summary.append(f\"    - AUC:       {test_metrics['auc']:.4f}\")\n",
        "                    summary.append(f\"    - MAP:       {test_metrics['map']:.4f}\")\n",
        "                    summary.append(f\"    - Recall:    {test_metrics['recall']:.4f}\")\n",
        "                elif class_name in self.config.CLASSES:\n",
        "                     summary.append(f\"\\n  {class_name}:\")\n",
        "                     summary.append(f\"    - Skipped due to insufficient samples.\")\n",
        "\n",
        "\n",
        "            # Multi-Class Results\n",
        "            if 'multiclass' in self.results[model_name] and self.results[model_name]['multiclass'].get('test_metrics'):\n",
        "                test_metrics = self.results[model_name]['multiclass']['test_metrics']\n",
        "                summary.append(f\"\\n  Multi-Class Classification Results:\")\n",
        "                summary.append(\"  \" + \"-\" * 38)\n",
        "                summary.append(f\"    - Accuracy:       {test_metrics['accuracy']:.2f}%\")\n",
        "                summary.append(f\"    - F1 Score:       {test_metrics['f1_score']:.4f}\")\n",
        "                summary.append(f\"    - AUC:            {test_metrics['auc']:.4f}\")\n",
        "                summary.append(f\"    - MAP:            {test_metrics['map']:.4f}\")\n",
        "                summary.append(f\"    - Recall:         {test_metrics['recall']:.4f}\")\n",
        "                summary.append(f\"    - Top-1 Accuracy: {test_metrics['top_1_accuracy']:.2f}%\")\n",
        "                if 'top_5_accuracy' in test_metrics:\n",
        "                    summary.append(f\"    - Top-5 Accuracy: {test_metrics['top_5_accuracy']:.2f}%\")\n",
        "\n",
        "        # Best performing model\n",
        "        summary.append(\"\\n\" + \"=\"*60)\n",
        "        summary.append(\"BEST PERFORMING MODELS\")\n",
        "        summary.append(\"=\"*60)\n",
        "\n",
        "        # Find best model for each metric\n",
        "        best_models = self._find_best_models()\n",
        "        for metric, (model, value) in best_models.items():\n",
        "            summary.append(f\"  {metric}: {model} ({value:.4f})\")\n",
        "\n",
        "        # Print and save report\n",
        "        report_text = '\\n'.join(summary)\n",
        "        print(report_text)\n",
        "\n",
        "        # Save to file\n",
        "        report_path = os.path.join(self.config.SAVE_DIR, \"federated_learning_report.txt\")\n",
        "        with open(report_path, 'w') as f:\n",
        "            f.write(report_text)\n",
        "\n",
        "        # Save as CSV for easier analysis\n",
        "        self._save_results_csv()\n",
        "\n",
        "        print(f\"\\nReport saved to {report_path}\")\n",
        "\n",
        "        return report_text\n",
        "\n",
        "\n",
        "    def _find_best_models(self):\n",
        "        \"\"\"\n",
        "        Find best performing models for each metric\n",
        "        \"\"\"\n",
        "        best_models = {}\n",
        "        metrics_to_check = ['accuracy', 'f1_score', 'auc', 'map', 'recall']\n",
        "\n",
        "        for metric in metrics_to_check:\n",
        "            best_value = -1\n",
        "            best_model = None\n",
        "\n",
        "            for model_name in self.results.keys():\n",
        "                if 'multiclass' in self.results[model_name] and self.results[model_name]['multiclass'].get('test_metrics'):\n",
        "                    test_metrics = self.results[model_name]['multiclass']['test_metrics']\n",
        "                    if metric in test_metrics:\n",
        "                        value = test_metrics[metric]\n",
        "                        if metric == 'accuracy':\n",
        "                            value = value / 100  # Convert percentage to decimal\n",
        "                        if value > best_value:\n",
        "                            best_value = value\n",
        "                            best_model = model_name\n",
        "\n",
        "            if best_model:\n",
        "                if metric == 'accuracy':\n",
        "                    best_value = best_value * 100  # Convert back to percentage\n",
        "                best_models[metric.upper()] = (best_model, best_value)\n",
        "\n",
        "        return best_models\n",
        "\n",
        "\n",
        "    def _save_results_csv(self):\n",
        "        \"\"\"\n",
        "        Save results as CSV for easier analysis\n",
        "        \"\"\"\n",
        "        # Prepare data for CSV\n",
        "        rows = []\n",
        "\n",
        "        for model_name in self.results.keys():\n",
        "            # Per-class results\n",
        "            for class_name in self.config.CLASSES:\n",
        "                if class_name in self.results[model_name] and self.results[model_name][class_name].get('test_metrics'):\n",
        "                    test_metrics = self.results[model_name][class_name]['test_metrics']\n",
        "                    row = {\n",
        "                        'Model': model_name,\n",
        "                        'Type': 'Binary',\n",
        "                        'Class': class_name,\n",
        "                        'Accuracy': test_metrics['accuracy'],\n",
        "                        'F1_Score': test_metrics['f1_score'],\n",
        "                        'AUC': test_metrics['auc'],\n",
        "                        'MAP': test_metrics['map'],\n",
        "                        'Recall': test_metrics['recall']\n",
        "                    }\n",
        "                    rows.append(row)\n",
        "                elif class_name in self.config.CLASSES:\n",
        "                    row = {\n",
        "                        'Model': model_name,\n",
        "                        'Type': 'Binary',\n",
        "                        'Class': class_name,\n",
        "                        'Accuracy': 'Skipped',\n",
        "                        'F1_Score': 'Skipped',\n",
        "                        'AUC': 'Skipped',\n",
        "                        'MAP': 'Skipped',\n",
        "                        'Recall': 'Skipped'\n",
        "                    }\n",
        "                    rows.append(row)\n",
        "\n",
        "\n",
        "            # Multi-class results\n",
        "            if 'multiclass' in self.results[model_name] and self.results[model_name]['multiclass'].get('test_metrics'):\n",
        "                test_metrics = self.results[model_name]['multiclass']['test_metrics']\n",
        "                row = {\n",
        "                    'Model': model_name,\n",
        "                    'Type': 'Multi-class',\n",
        "                    'Class': 'All',\n",
        "                    'Accuracy': test_metrics['accuracy'],\n",
        "                    'F1_Score': test_metrics['f1_score'],\n",
        "                    'AUC': test_metrics['auc'],\n",
        "                    'MAP': test_metrics['map'],\n",
        "                    'Recall': test_metrics['recall']\n",
        "                }\n",
        "                rows.append(row)\n",
        "\n",
        "        # Save to CSV\n",
        "        if rows:\n",
        "            df = pd.DataFrame(rows)\n",
        "            csv_path = os.path.join(self.config.SAVE_DIR, \"federated_results.csv\")\n",
        "            df.to_csv(csv_path, index=False)\n",
        "            print(f\"Results CSV saved to {csv_path}\")\n",
        "\n",
        "\n",
        "    def run_complete_pipeline(self):\n",
        "        \"\"\"\n",
        "        Run the complete federated learning pipeline\n",
        "        \"\"\"\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(\"STARTING FEDERATED LEARNING PIPELINE FOR CHEXPERT DATASET\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        # Load data\n",
        "        self.load_data()\n",
        "\n",
        "        # Models to train\n",
        "        models = [\"resnet18\", \"densenet121\", \"efficientnet\"]\n",
        "\n",
        "        for model_name in models:\n",
        "            print(f\"\\n\\n{'#'*60}\")\n",
        "            print(f\"TRAINING MODEL: {model_name.upper()}\")\n",
        "            print(f\"{'#'*60}\")\n",
        "\n",
        "            # Train per-class models\n",
        "            for i, class_name in enumerate(self.config.CLASSES):\n",
        "                try:\n",
        "                    self.train_per_class_federated(model_name, i, class_name)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error training {model_name} for {class_name}: {str(e)}\")\n",
        "                    # Ensure an empty entry exists in results for skipped classes\n",
        "                    if class_name not in self.results[model_name]:\n",
        "                         self.results[model_name][class_name] = {\n",
        "                            'training_metrics': {},\n",
        "                            'test_metrics': {},\n",
        "                            'confusion_matrix': np.zeros((2, 2))\n",
        "                        }\n",
        "\n",
        "                    continue\n",
        "\n",
        "            # Train multi-class model\n",
        "            try:\n",
        "                self.train_multiclass_federated(model_name)\n",
        "            except Exception as e:\n",
        "                print(f\"Error training multi-class {model_name}: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "            # Generate visualizations\n",
        "            self.visualize_results(model_name)\n",
        "\n",
        "        # Generate summary report\n",
        "        self.generate_summary_report()\n",
        "\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(\"FEDERATED LEARNING PIPELINE COMPLETED SUCCESSFULLY!\")\n",
        "        print(f\"{'='*70}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKjEIO2iRTw4"
      },
      "outputs": [],
      "source": [
        "# Main execution\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to run the federated learning pipeline\n",
        "    \"\"\"\n",
        "    # Initialize configuration\n",
        "    config = Config()\n",
        "\n",
        "    print(\"Federated Learning Pipeline for CheXpert Dataset\")\n",
        "    print(f\"Configuration:\")\n",
        "    print(f\"  - Classes: {config.CLASSES}\")\n",
        "    print(f\"  - Clients: {config.NUM_CLIENTS}\")\n",
        "    print(f\"  - Rounds: {config.NUM_ROUNDS}\")\n",
        "    print(f\"  - Device: {config.DEVICE}\")\n",
        "\n",
        "    # Initialize pipeline\n",
        "    pipeline = FederatedLearningPipeline(config)\n",
        "\n",
        "    # Run complete pipeline\n",
        "    pipeline.run_complete_pipeline()\n",
        "\n",
        "    return pipeline\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hX6zI-E2RV6l",
        "outputId": "0f9f43ef-8a55-4e33-ce53-32f2e9c68027"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Installing scikit-learn...\n",
            "Federated Learning Pipeline for CheXpert Dataset\n",
            "Configuration:\n",
            "  - Classes: ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural_Effusion']\n",
            "  - Clients: 5\n",
            "  - Rounds: 10\n",
            "  - Device: cuda\n",
            "\n",
            "======================================================================\n",
            "STARTING FEDERATED LEARNING PIPELINE FOR CHEXPERT DATASET\n",
            "======================================================================\n",
            "Loading CheXpert dataset from folders...\n",
            "OSError reading directory /content/drive/MyDrive/Colab_Datasets/chexpert_dataset/train/Pleural_Effusion: [Errno 5] Input/output error: '/content/drive/MyDrive/Colab_Datasets/chexpert_dataset/train/Pleural_Effusion'. Attempt 1/5.\n",
            "OSError reading directory /content/drive/MyDrive/Colab_Datasets/chexpert_dataset/train/Pleural_Effusion: [Errno 5] Input/output error: '/content/drive/MyDrive/Colab_Datasets/chexpert_dataset/train/Pleural_Effusion'. Attempt 2/5.\n",
            "Loaded 5000 total samples from /content/drive/MyDrive/Colab_Datasets/chexpert_dataset/train\n",
            "  Atelectasis: 1000 samples\n",
            "  Cardiomegaly: 1000 samples\n",
            "  Consolidation: 1000 samples\n",
            "  Edema: 1000 samples\n",
            "  Pleural_Effusion: 1000 samples\n",
            "Loaded 1000 total samples from /content/drive/MyDrive/Colab_Datasets/chexpert_dataset/test\n",
            "  Atelectasis: 200 samples\n",
            "  Cardiomegaly: 200 samples\n",
            "  Consolidation: 200 samples\n",
            "  Edema: 200 samples\n",
            "  Pleural_Effusion: 200 samples\n",
            "\n",
            "Dataset Summary:\n",
            "Train dataset size: 5000\n",
            "Test dataset size: 1000\n",
            "\n",
            "\n",
            "############################################################\n",
            "TRAINING MODEL: RESNET18\n",
            "############################################################\n",
            "\n",
            "==================================================\n",
            "Training resnet18 for class: Atelectasis\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|| 44.7M/44.7M [00:04<00:00, 10.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Round 1/10\n",
            "Avg Train Loss: 0.7342, Avg Train Acc: 58.67%\n",
            "Avg Val Loss: 0.6949, Avg Val Acc: 52.50%\n",
            "F1 Score: 0.3615, AUC: 0.5421, MAP: 0.5139\n",
            "\n",
            "Round 2/10\n",
            "Avg Train Loss: 0.6194, Avg Train Acc: 66.14%\n",
            "Avg Val Loss: 0.7023, Avg Val Acc: 52.25%\n",
            "F1 Score: 0.5074, AUC: 0.5869, MAP: 0.5782\n",
            "\n",
            "Round 3/10\n",
            "Avg Train Loss: 0.5358, Avg Train Acc: 73.15%\n",
            "Avg Val Loss: 0.7129, Avg Val Acc: 58.00%\n",
            "F1 Score: 0.5794, AUC: 0.6071, MAP: 0.5812\n",
            "\n",
            "Round 4/10\n",
            "Avg Train Loss: 0.4552, Avg Train Acc: 78.38%\n",
            "Avg Val Loss: 0.7726, Avg Val Acc: 58.75%\n",
            "F1 Score: 0.5846, AUC: 0.6247, MAP: 0.5922\n",
            "\n",
            "Round 5/10\n",
            "Avg Train Loss: 0.3954, Avg Train Acc: 82.41%\n",
            "Avg Val Loss: 0.7693, Avg Val Acc: 60.25%\n",
            "F1 Score: 0.6023, AUC: 0.6229, MAP: 0.5964\n",
            "\n",
            "Round 6/10\n",
            "Avg Train Loss: 0.3295, Avg Train Acc: 85.58%\n",
            "Avg Val Loss: 0.9003, Avg Val Acc: 59.25%\n",
            "F1 Score: 0.5884, AUC: 0.6186, MAP: 0.5859\n",
            "\n",
            "Round 7/10\n",
            "Avg Train Loss: 0.2927, Avg Train Acc: 87.58%\n",
            "Avg Val Loss: 0.8999, Avg Val Acc: 58.25%\n",
            "F1 Score: 0.5779, AUC: 0.6046, MAP: 0.5815\n",
            "\n",
            "Round 8/10\n",
            "Avg Train Loss: 0.2613, Avg Train Acc: 89.22%\n",
            "Avg Val Loss: 0.9170, Avg Val Acc: 58.75%\n",
            "F1 Score: 0.5874, AUC: 0.6217, MAP: 0.5721\n",
            "\n",
            "Round 9/10\n",
            "Avg Train Loss: 0.2432, Avg Train Acc: 89.84%\n",
            "Avg Val Loss: 1.1268, Avg Val Acc: 57.00%\n",
            "F1 Score: 0.5331, AUC: 0.6167, MAP: 0.5929\n",
            "\n",
            "Round 10/10\n",
            "Avg Train Loss: 0.1855, Avg Train Acc: 92.62%\n",
            "Avg Val Loss: 0.9887, Avg Val Acc: 58.75%\n",
            "F1 Score: 0.5791, AUC: 0.6138, MAP: 0.5790\n",
            "\n",
            "Test Results:\n",
            "Test Loss: 0.9638\n",
            "Test Accuracy: 56.50%\n",
            "Test F1 Score: 0.5504\n",
            "Test AUC: 0.6134\n",
            "Test MAP: 0.6354\n",
            "Test Recall: 0.5650\n",
            "Model saved to /content/drive/MyDrive/Colab_Datasets/federated_models/resnet18_Atelectasis_model.pth\n",
            "\n",
            "==================================================\n",
            "Training resnet18 for class: Cardiomegaly\n",
            "==================================================\n",
            "\n",
            "Round 1/10\n",
            "Avg Train Loss: 0.7390, Avg Train Acc: 58.95%\n",
            "Avg Val Loss: 0.6994, Avg Val Acc: 49.50%\n",
            "F1 Score: 0.3278, AUC: 0.5393, MAP: 0.5607\n",
            "\n",
            "Round 2/10\n",
            "Avg Train Loss: 0.6256, Avg Train Acc: 64.94%\n",
            "Avg Val Loss: 0.6560, Avg Val Acc: 64.00%\n",
            "F1 Score: 0.6394, AUC: 0.6764, MAP: 0.6723\n",
            "\n",
            "Round 3/10\n",
            "Avg Train Loss: 0.5378, Avg Train Acc: 73.11%\n",
            "Avg Val Loss: 0.6059, Avg Val Acc: 65.25%\n",
            "F1 Score: 0.6514, AUC: 0.7274, MAP: 0.7261\n",
            "\n",
            "Round 4/10\n",
            "Avg Train Loss: 0.4262, Avg Train Acc: 80.66%\n",
            "Avg Val Loss: 0.6204, Avg Val Acc: 68.25%\n",
            "F1 Score: 0.6801, AUC: 0.7568, MAP: 0.7472\n",
            "\n",
            "Round 5/10\n",
            "Avg Train Loss: 0.3705, Avg Train Acc: 83.41%\n",
            "Avg Val Loss: 0.6376, Avg Val Acc: 71.25%\n",
            "F1 Score: 0.7081, AUC: 0.7621, MAP: 0.7418\n",
            "\n",
            "Round 6/10\n",
            "Avg Train Loss: 0.3135, Avg Train Acc: 86.61%\n",
            "Avg Val Loss: 0.9153, Avg Val Acc: 65.25%\n",
            "F1 Score: 0.6211, AUC: 0.7290, MAP: 0.6984\n",
            "\n",
            "Round 7/10\n",
            "Avg Train Loss: 0.2683, Avg Train Acc: 88.84%\n",
            "Avg Val Loss: 0.7283, Avg Val Acc: 68.00%\n",
            "F1 Score: 0.6789, AUC: 0.7401, MAP: 0.7118\n",
            "\n",
            "Round 8/10\n",
            "Avg Train Loss: 0.2250, Avg Train Acc: 90.85%\n",
            "Avg Val Loss: 1.0052, Avg Val Acc: 65.00%\n",
            "F1 Score: 0.6246, AUC: 0.7341, MAP: 0.7022\n",
            "\n",
            "Round 9/10\n",
            "Avg Train Loss: 0.2382, Avg Train Acc: 90.42%\n",
            "Avg Val Loss: 0.8623, Avg Val Acc: 65.25%\n",
            "F1 Score: 0.6223, AUC: 0.7241, MAP: 0.6989\n",
            "\n",
            "Round 10/10\n",
            "Avg Train Loss: 0.1734, Avg Train Acc: 93.34%\n",
            "Avg Val Loss: 0.8706, Avg Val Acc: 66.50%\n",
            "F1 Score: 0.6650, AUC: 0.7214, MAP: 0.6900\n",
            "\n",
            "Test Results:\n",
            "Test Loss: 0.7585\n",
            "Test Accuracy: 66.50%\n",
            "Test F1 Score: 0.6650\n",
            "Test AUC: 0.7411\n",
            "Test MAP: 0.7490\n",
            "Test Recall: 0.6650\n",
            "Model saved to /content/drive/MyDrive/Colab_Datasets/federated_models/resnet18_Cardiomegaly_model.pth\n",
            "\n",
            "==================================================\n",
            "Training resnet18 for class: Consolidation\n",
            "==================================================\n",
            "\n",
            "Round 1/10\n",
            "Avg Train Loss: 0.7332, Avg Train Acc: 58.96%\n",
            "Avg Val Loss: 0.7047, Avg Val Acc: 50.50%\n",
            "F1 Score: 0.3389, AUC: 0.4755, MAP: 0.5127\n",
            "\n",
            "Round 2/10\n",
            "Avg Train Loss: 0.6216, Avg Train Acc: 64.96%\n",
            "Avg Val Loss: 0.6585, Avg Val Acc: 59.50%\n",
            "F1 Score: 0.5829, AUC: 0.6533, MAP: 0.6760\n",
            "\n",
            "Round 3/10\n",
            "Avg Train Loss: 0.5207, Avg Train Acc: 73.78%\n",
            "Avg Val Loss: 0.6894, Avg Val Acc: 60.25%\n",
            "F1 Score: 0.5930, AUC: 0.6596, MAP: 0.6812\n",
            "\n",
            "Round 4/10\n",
            "Avg Train Loss: 0.4470, Avg Train Acc: 78.66%\n",
            "Avg Val Loss: 0.7430, Avg Val Acc: 59.25%\n",
            "F1 Score: 0.5467, AUC: 0.6656, MAP: 0.6785\n",
            "\n",
            "Round 5/10\n",
            "Avg Train Loss: 0.3922, Avg Train Acc: 82.01%\n",
            "Avg Val Loss: 0.7286, Avg Val Acc: 61.00%\n",
            "F1 Score: 0.6100, AUC: 0.6579, MAP: 0.6592\n",
            "\n",
            "Round 6/10\n",
            "Avg Train Loss: 0.3272, Avg Train Acc: 85.72%\n",
            "Avg Val Loss: 0.7835, Avg Val Acc: 58.25%\n",
            "F1 Score: 0.5789, AUC: 0.6393, MAP: 0.6441\n",
            "\n",
            "Round 7/10\n",
            "Avg Train Loss: 0.2874, Avg Train Acc: 87.55%\n",
            "Avg Val Loss: 0.9193, Avg Val Acc: 60.50%\n",
            "F1 Score: 0.5918, AUC: 0.6525, MAP: 0.6636\n",
            "\n",
            "Round 8/10\n",
            "Avg Train Loss: 0.2658, Avg Train Acc: 88.85%\n",
            "Avg Val Loss: 0.9164, Avg Val Acc: 57.75%\n",
            "F1 Score: 0.5735, AUC: 0.6227, MAP: 0.6386\n",
            "\n",
            "Round 9/10\n",
            "Avg Train Loss: 0.2140, Avg Train Acc: 91.11%\n",
            "Avg Val Loss: 1.1546, Avg Val Acc: 57.50%\n",
            "F1 Score: 0.5401, AUC: 0.6350, MAP: 0.6286\n",
            "\n",
            "Round 10/10\n",
            "Avg Train Loss: 0.2019, Avg Train Acc: 91.89%\n",
            "Avg Val Loss: 1.0046, Avg Val Acc: 58.75%\n",
            "F1 Score: 0.5770, AUC: 0.6279, MAP: 0.6378\n",
            "\n",
            "Test Results:\n",
            "Test Loss: 1.0486\n",
            "Test Accuracy: 58.50%\n",
            "Test F1 Score: 0.5726\n",
            "Test AUC: 0.6217\n",
            "Test MAP: 0.6286\n",
            "Test Recall: 0.5850\n",
            "Model saved to /content/drive/MyDrive/Colab_Datasets/federated_models/resnet18_Consolidation_model.pth\n",
            "\n",
            "==================================================\n",
            "Training resnet18 for class: Edema\n",
            "==================================================\n",
            "\n",
            "Round 1/10\n",
            "Avg Train Loss: 0.7325, Avg Train Acc: 59.74%\n",
            "Avg Val Loss: 0.7531, Avg Val Acc: 46.00%\n",
            "F1 Score: 0.2899, AUC: 0.5385, MAP: 0.4879\n",
            "\n",
            "Round 2/10\n",
            "Avg Train Loss: 0.6037, Avg Train Acc: 67.17%\n",
            "Avg Val Loss: 0.6967, Avg Val Acc: 55.50%\n",
            "F1 Score: 0.5418, AUC: 0.5916, MAP: 0.5458\n",
            "\n",
            "Round 3/10\n",
            "Avg Train Loss: 0.5141, Avg Train Acc: 74.91%\n",
            "Avg Val Loss: 0.7247, Avg Val Acc: 55.00%\n",
            "F1 Score: 0.5412, AUC: 0.6035, MAP: 0.5667\n",
            "\n",
            "Round 4/10\n",
            "Avg Train Loss: 0.4519, Avg Train Acc: 79.14%\n",
            "Avg Val Loss: 0.7330, Avg Val Acc: 54.75%\n",
            "F1 Score: 0.5418, AUC: 0.5832, MAP: 0.5378\n",
            "\n",
            "Round 5/10\n",
            "Avg Train Loss: 0.3797, Avg Train Acc: 82.99%\n",
            "Avg Val Loss: 0.9140, Avg Val Acc: 50.50%\n",
            "F1 Score: 0.4388, AUC: 0.5853, MAP: 0.5403\n",
            "\n",
            "Round 6/10\n",
            "Avg Train Loss: 0.3163, Avg Train Acc: 86.25%\n",
            "Avg Val Loss: 0.8742, Avg Val Acc: 53.00%\n",
            "F1 Score: 0.5208, AUC: 0.6053, MAP: 0.5910\n",
            "\n",
            "Round 7/10\n",
            "Avg Train Loss: 0.2894, Avg Train Acc: 87.70%\n",
            "Avg Val Loss: 0.8952, Avg Val Acc: 55.00%\n",
            "F1 Score: 0.5471, AUC: 0.5809, MAP: 0.5213\n",
            "\n",
            "Round 8/10\n",
            "Avg Train Loss: 0.2612, Avg Train Acc: 89.78%\n",
            "Avg Val Loss: 0.9259, Avg Val Acc: 54.75%\n",
            "F1 Score: 0.5272, AUC: 0.6055, MAP: 0.5559\n",
            "\n",
            "Round 9/10\n",
            "Avg Train Loss: 0.2472, Avg Train Acc: 89.86%\n",
            "Avg Val Loss: 0.9253, Avg Val Acc: 55.50%\n",
            "F1 Score: 0.5393, AUC: 0.5939, MAP: 0.5280\n",
            "\n",
            "Round 10/10\n",
            "Avg Train Loss: 0.1770, Avg Train Acc: 93.01%\n",
            "Avg Val Loss: 1.0667, Avg Val Acc: 55.75%\n",
            "F1 Score: 0.5555, AUC: 0.5671, MAP: 0.5108\n",
            "\n",
            "Test Results:\n",
            "Test Loss: 1.0084\n",
            "Test Accuracy: 59.50%\n",
            "Test F1 Score: 0.5900\n",
            "Test AUC: 0.6213\n",
            "Test MAP: 0.6135\n",
            "Test Recall: 0.5950\n",
            "Model saved to /content/drive/MyDrive/Colab_Datasets/federated_models/resnet18_Edema_model.pth\n",
            "\n",
            "==================================================\n",
            "Training resnet18 for class: Pleural_Effusion\n",
            "==================================================\n",
            "\n",
            "Round 1/10\n",
            "Avg Train Loss: 0.7525, Avg Train Acc: 57.67%\n",
            "Avg Val Loss: 0.6979, Avg Val Acc: 46.50%\n",
            "F1 Score: 0.2952, AUC: 0.5137, MAP: 0.5493\n",
            "\n",
            "Round 2/10\n",
            "Avg Train Loss: 0.6224, Avg Train Acc: 64.50%\n",
            "Avg Val Loss: 0.6710, Avg Val Acc: 58.00%\n",
            "F1 Score: 0.5426, AUC: 0.5945, MAP: 0.6427\n",
            "\n",
            "Round 3/10\n",
            "Avg Train Loss: 0.5294, Avg Train Acc: 72.71%\n",
            "Avg Val Loss: 0.6964, Avg Val Acc: 57.50%\n",
            "F1 Score: 0.5693, AUC: 0.5974, MAP: 0.6366\n",
            "\n",
            "Round 4/10\n",
            "Avg Train Loss: 0.4366, Avg Train Acc: 79.40%\n",
            "Avg Val Loss: 0.7222, Avg Val Acc: 54.25%\n",
            "F1 Score: 0.5391, AUC: 0.6126, MAP: 0.6507\n",
            "\n",
            "Round 5/10\n",
            "Avg Train Loss: 0.3790, Avg Train Acc: 82.91%\n",
            "Avg Val Loss: 0.7761, Avg Val Acc: 58.25%\n",
            "F1 Score: 0.5488, AUC: 0.6029, MAP: 0.6230\n",
            "\n",
            "Round 6/10\n",
            "Avg Train Loss: 0.3202, Avg Train Acc: 86.08%\n",
            "Avg Val Loss: 0.8386, Avg Val Acc: 56.50%\n",
            "F1 Score: 0.5071, AUC: 0.6010, MAP: 0.6318\n",
            "\n",
            "Round 7/10\n",
            "Avg Train Loss: 0.2872, Avg Train Acc: 87.92%\n",
            "Avg Val Loss: 0.7964, Avg Val Acc: 58.75%\n",
            "F1 Score: 0.5710, AUC: 0.6293, MAP: 0.6494\n",
            "\n",
            "Round 8/10\n",
            "Avg Train Loss: 0.2545, Avg Train Acc: 89.06%\n",
            "Avg Val Loss: 0.8409, Avg Val Acc: 57.50%\n",
            "F1 Score: 0.5400, AUC: 0.6116, MAP: 0.6533\n",
            "\n",
            "Round 9/10\n",
            "Avg Train Loss: 0.2117, Avg Train Acc: 91.53%\n",
            "Avg Val Loss: 0.9200, Avg Val Acc: 57.25%\n",
            "F1 Score: 0.5613, AUC: 0.6212, MAP: 0.6210\n",
            "\n",
            "Round 10/10\n",
            "Avg Train Loss: 0.1960, Avg Train Acc: 92.01%\n",
            "Avg Val Loss: 0.8277, Avg Val Acc: 57.50%\n",
            "F1 Score: 0.5724, AUC: 0.6401, MAP: 0.6473\n",
            "\n",
            "Test Results:\n",
            "Test Loss: 0.9067\n",
            "Test Accuracy: 57.25%\n",
            "Test F1 Score: 0.5623\n",
            "Test AUC: 0.6176\n",
            "Test MAP: 0.5866\n",
            "Test Recall: 0.5725\n",
            "Model saved to /content/drive/MyDrive/Colab_Datasets/federated_models/resnet18_Pleural_Effusion_model.pth\n",
            "\n",
            "==================================================\n",
            "Training resnet18 for Multi-Class Classification\n",
            "==================================================\n",
            "\n",
            "Round 1/10\n",
            "Avg Train Loss: 1.6117, Avg Train Acc: 27.48%\n",
            "Avg Val Loss: 1.6438, Avg Val Acc: 21.20%\n",
            "F1 Score: 0.0742, AUC: 0.5456, MAP: 0.2239\n",
            "\n",
            "Round 2/10\n",
            "Avg Train Loss: 1.5696, Avg Train Acc: 29.02%\n",
            "Avg Val Loss: 1.6345, Avg Val Acc: 21.90%\n",
            "F1 Score: 0.0949, AUC: 0.6161, MAP: 0.2806\n",
            "\n",
            "Round 3/10\n",
            "Avg Train Loss: 1.5020, Avg Train Acc: 34.64%\n",
            "Avg Val Loss: 1.5735, Avg Val Acc: 26.30%\n",
            "F1 Score: 0.2009, AUC: 0.6474, MAP: 0.3090\n",
            "\n",
            "Round 4/10\n",
            "Avg Train Loss: 1.4107, Avg Train Acc: 40.19%\n",
            "Avg Val Loss: 1.5470, Avg Val Acc: 32.60%\n",
            "F1 Score: 0.2996, AUC: 0.6511, MAP: 0.3105\n",
            "\n",
            "Round 5/10\n",
            "Avg Train Loss: 1.2782, Avg Train Acc: 48.26%\n",
            "Avg Val Loss: 1.6214, Avg Val Acc: 30.40%\n",
            "F1 Score: 0.2812, AUC: 0.6569, MAP: 0.3165\n",
            "\n",
            "Round 6/10\n",
            "Avg Train Loss: 1.1410, Avg Train Acc: 54.80%\n",
            "Avg Val Loss: 1.7358, Avg Val Acc: 30.90%\n",
            "F1 Score: 0.2925, AUC: 0.6532, MAP: 0.3135\n",
            "\n",
            "Round 7/10\n",
            "Avg Train Loss: 0.9908, Avg Train Acc: 61.90%\n",
            "Avg Val Loss: 1.9109, Avg Val Acc: 30.60%\n",
            "F1 Score: 0.2891, AUC: 0.6403, MAP: 0.3000\n",
            "\n",
            "Round 8/10\n",
            "Avg Train Loss: 0.8293, Avg Train Acc: 68.78%\n",
            "Avg Val Loss: 2.0212, Avg Val Acc: 30.80%\n",
            "F1 Score: 0.2883, AUC: 0.6282, MAP: 0.2950\n",
            "\n",
            "Round 9/10\n",
            "Avg Train Loss: 0.6877, Avg Train Acc: 74.61%\n",
            "Avg Val Loss: 2.1068, Avg Val Acc: 31.50%\n",
            "F1 Score: 0.3012, AUC: 0.6421, MAP: 0.3058\n",
            "\n",
            "Round 10/10\n",
            "Avg Train Loss: 0.5782, Avg Train Acc: 79.03%\n",
            "Avg Val Loss: 2.1561, Avg Val Acc: 30.00%\n",
            "F1 Score: 0.2953, AUC: 0.6264, MAP: 0.2854\n",
            "\n",
            "Test Results:\n",
            "Test Loss: 2.0609\n",
            "Test Accuracy: 34.00%\n",
            "Test F1 Score: 0.3375\n",
            "Test AUC: 0.6468\n",
            "Test MAP: 0.3176\n",
            "Test Recall: 0.3400\n",
            "Model saved to /content/drive/MyDrive/Colab_Datasets/federated_models/resnet18_multiclass_model.pth\n",
            "\n",
            "==================================================\n",
            "Generating Visualizations for resnet18\n",
            "==================================================\n",
            "Visualizations saved to /content/drive/MyDrive/Colab_Datasets/federated_models/resnet18_figures\n",
            "\n",
            "\n",
            "############################################################\n",
            "TRAINING MODEL: DENSENET121\n",
            "############################################################\n",
            "\n",
            "==================================================\n",
            "Training densenet121 for class: Atelectasis\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n",
            "100%|| 30.8M/30.8M [00:01<00:00, 24.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Round 1/10\n",
            "Avg Train Loss: 0.6926, Avg Train Acc: 58.80%\n",
            "Avg Val Loss: 0.6928, Avg Val Acc: 55.75%\n",
            "F1 Score: 0.5249, AUC: 0.5720, MAP: 0.6046\n",
            "\n",
            "Round 2/10\n",
            "Avg Train Loss: 0.6176, Avg Train Acc: 65.65%\n",
            "Avg Val Loss: 0.7178, Avg Val Acc: 50.50%\n",
            "F1 Score: 0.3749, AUC: 0.6896, MAP: 0.7126\n",
            "\n",
            "Round 3/10\n",
            "Avg Train Loss: 0.5444, Avg Train Acc: 72.08%\n",
            "Avg Val Loss: 1.0774, Avg Val Acc: 47.25%\n",
            "F1 Score: 0.3032, AUC: 0.6902, MAP: 0.7033\n",
            "\n",
            "Round 4/10\n",
            "Avg Train Loss: 0.4538, Avg Train Acc: 78.70%\n",
            "Avg Val Loss: 1.0707, Avg Val Acc: 49.00%\n",
            "F1 Score: 0.3447, AUC: 0.6928, MAP: 0.7106\n",
            "\n",
            "Round 5/10\n",
            "Avg Train Loss: 0.3816, Avg Train Acc: 82.91%\n",
            "Avg Val Loss: 1.2362, Avg Val Acc: 48.25%\n",
            "F1 Score: 0.3290, AUC: 0.6830, MAP: 0.6994\n",
            "\n",
            "Round 6/10\n",
            "Avg Train Loss: 0.3290, Avg Train Acc: 85.47%\n",
            "Avg Val Loss: 1.1280, Avg Val Acc: 47.75%\n",
            "F1 Score: 0.3345, AUC: 0.6684, MAP: 0.6846\n",
            "\n",
            "Round 7/10\n",
            "Avg Train Loss: 0.2785, Avg Train Acc: 88.01%\n",
            "Avg Val Loss: 1.2177, Avg Val Acc: 49.00%\n",
            "F1 Score: 0.3523, AUC: 0.6731, MAP: 0.6838\n",
            "\n",
            "Round 8/10\n",
            "Avg Train Loss: 0.2418, Avg Train Acc: 89.81%\n",
            "Avg Val Loss: 1.1677, Avg Val Acc: 51.00%\n",
            "F1 Score: 0.3945, AUC: 0.6715, MAP: 0.6883\n",
            "\n",
            "Round 9/10\n",
            "Avg Train Loss: 0.2120, Avg Train Acc: 91.53%\n",
            "Avg Val Loss: 1.2955, Avg Val Acc: 50.50%\n",
            "F1 Score: 0.3947, AUC: 0.6785, MAP: 0.6905\n",
            "\n",
            "Round 10/10\n",
            "Avg Train Loss: 0.2036, Avg Train Acc: 91.26%\n",
            "Avg Val Loss: 1.5343, Avg Val Acc: 48.75%\n",
            "F1 Score: 0.3581, AUC: 0.6791, MAP: 0.6848\n",
            "\n",
            "Test Results:\n",
            "Test Loss: 1.5226\n",
            "Test Accuracy: 51.25%\n",
            "Test F1 Score: 0.3762\n",
            "Test AUC: 0.5815\n",
            "Test MAP: 0.5876\n",
            "Test Recall: 0.5125\n",
            "Model saved to /content/drive/MyDrive/Colab_Datasets/federated_models/densenet121_Atelectasis_model.pth\n",
            "\n",
            "==================================================\n",
            "Training densenet121 for class: Cardiomegaly\n",
            "==================================================\n",
            "\n",
            "Round 1/10\n",
            "Avg Train Loss: 0.6706, Avg Train Acc: 60.46%\n",
            "Avg Val Loss: 0.6915, Avg Val Acc: 57.75%\n",
            "F1 Score: 0.5777, AUC: 0.5778, MAP: 0.6102\n",
            "\n",
            "Round 2/10\n",
            "Avg Train Loss: 0.5904, Avg Train Acc: 68.25%\n",
            "Avg Val Loss: 0.6466, Avg Val Acc: 64.75%\n",
            "F1 Score: 0.6278, AUC: 0.6865, MAP: 0.6884\n",
            "\n",
            "Round 3/10\n",
            "Avg Train Loss: 0.4872, Avg Train Acc: 76.44%\n",
            "Avg Val Loss: 0.6789, Avg Val Acc: 59.00%\n",
            "F1 Score: 0.5763, AUC: 0.6936, MAP: 0.6965\n",
            "\n",
            "Round 4/10\n",
            "Avg Train Loss: 0.3745, Avg Train Acc: 82.84%\n",
            "Avg Val Loss: 0.6887, Avg Val Acc: 64.75%\n",
            "F1 Score: 0.6434, AUC: 0.7031, MAP: 0.7099\n",
            "\n",
            "Round 5/10\n",
            "Avg Train Loss: 0.3102, Avg Train Acc: 86.69%\n",
            "Avg Val Loss: 0.7280, Avg Val Acc: 65.50%\n",
            "F1 Score: 0.6551, AUC: 0.7049, MAP: 0.6880\n",
            "\n",
            "Round 6/10\n",
            "Avg Train Loss: 0.2912, Avg Train Acc: 87.88%\n",
            "Avg Val Loss: 0.7502, Avg Val Acc: 64.75%\n",
            "F1 Score: 0.6473, AUC: 0.6996, MAP: 0.6939\n",
            "\n",
            "Round 7/10\n",
            "Avg Train Loss: 0.2509, Avg Train Acc: 89.36%\n",
            "Avg Val Loss: 0.7835, Avg Val Acc: 66.50%\n",
            "F1 Score: 0.6643, AUC: 0.7129, MAP: 0.7033\n",
            "\n",
            "Round 8/10\n",
            "Avg Train Loss: 0.2091, Avg Train Acc: 91.66%\n",
            "Avg Val Loss: 0.8542, Avg Val Acc: 65.75%\n",
            "F1 Score: 0.6543, AUC: 0.7087, MAP: 0.7039\n",
            "\n",
            "Round 9/10\n",
            "Avg Train Loss: 0.1794, Avg Train Acc: 92.75%\n",
            "Avg Val Loss: 0.9119, Avg Val Acc: 64.75%\n",
            "F1 Score: 0.6442, AUC: 0.6937, MAP: 0.6861\n",
            "\n",
            "Round 10/10\n",
            "Avg Train Loss: 0.1765, Avg Train Acc: 92.71%\n",
            "Avg Val Loss: 0.9472, Avg Val Acc: 65.25%\n",
            "F1 Score: 0.6499, AUC: 0.6926, MAP: 0.6843\n",
            "\n",
            "Test Results:\n",
            "Test Loss: 0.9503\n",
            "Test Accuracy: 66.75%\n",
            "Test F1 Score: 0.6672\n",
            "Test AUC: 0.7127\n",
            "Test MAP: 0.6978\n",
            "Test Recall: 0.6675\n",
            "Model saved to /content/drive/MyDrive/Colab_Datasets/federated_models/densenet121_Cardiomegaly_model.pth\n",
            "\n",
            "==================================================\n",
            "Training densenet121 for class: Consolidation\n",
            "==================================================\n",
            "\n",
            "Round 1/10\n",
            "Avg Train Loss: 0.6819, Avg Train Acc: 59.61%\n",
            "Avg Val Loss: 0.6928, Avg Val Acc: 49.75%\n",
            "F1 Score: 0.4261, AUC: 0.5689, MAP: 0.5420\n",
            "\n",
            "Round 2/10\n",
            "Avg Train Loss: 0.6142, Avg Train Acc: 65.81%\n",
            "Avg Val Loss: 0.8051, Avg Val Acc: 47.25%\n",
            "F1 Score: 0.3103, AUC: 0.6523, MAP: 0.6252\n",
            "\n",
            "Round 3/10\n",
            "Avg Train Loss: 0.5157, Avg Train Acc: 74.00%\n",
            "Avg Val Loss: 0.7569, Avg Val Acc: 53.50%\n",
            "F1 Score: 0.4518, AUC: 0.6779, MAP: 0.6480\n",
            "\n",
            "Round 4/10\n",
            "Avg Train Loss: 0.4202, Avg Train Acc: 80.47%\n",
            "Avg Val Loss: 0.8898, Avg Val Acc: 52.75%\n",
            "F1 Score: 0.4490, AUC: 0.6643, MAP: 0.6381\n",
            "\n",
            "Round 5/10\n",
            "Avg Train Loss: 0.3545, Avg Train Acc: 84.51%\n",
            "Avg Val Loss: 0.7975, Avg Val Acc: 55.75%\n",
            "F1 Score: 0.5244, AUC: 0.6948, MAP: 0.6627\n",
            "\n",
            "Round 6/10\n",
            "Avg Train Loss: 0.3092, Avg Train Acc: 86.78%\n",
            "Avg Val Loss: 0.9556, Avg Val Acc: 54.75%\n",
            "F1 Score: 0.4929, AUC: 0.6662, MAP: 0.6512\n",
            "\n",
            "Round 7/10\n",
            "Avg Train Loss: 0.2638, Avg Train Acc: 88.69%\n",
            "Avg Val Loss: 0.9380, Avg Val Acc: 58.75%\n",
            "F1 Score: 0.5602, AUC: 0.6925, MAP: 0.6608\n",
            "\n",
            "Round 8/10\n",
            "Avg Train Loss: 0.2250, Avg Train Acc: 90.74%\n",
            "Avg Val Loss: 0.9949, Avg Val Acc: 58.25%\n",
            "F1 Score: 0.5572, AUC: 0.6841, MAP: 0.6599\n",
            "\n",
            "Round 9/10\n",
            "Avg Train Loss: 0.2140, Avg Train Acc: 91.39%\n",
            "Avg Val Loss: 1.2311, Avg Val Acc: 56.00%\n",
            "F1 Score: 0.5112, AUC: 0.6863, MAP: 0.6591\n",
            "\n",
            "Round 10/10\n",
            "Avg Train Loss: 0.1805, Avg Train Acc: 92.83%\n",
            "Avg Val Loss: 1.0694, Avg Val Acc: 56.75%\n",
            "F1 Score: 0.5424, AUC: 0.6649, MAP: 0.6334\n",
            "\n",
            "Test Results:\n",
            "Test Loss: 1.1297\n",
            "Test Accuracy: 57.75%\n",
            "Test F1 Score: 0.5499\n",
            "Test AUC: 0.6511\n",
            "Test MAP: 0.6561\n",
            "Test Recall: 0.5775\n",
            "Model saved to /content/drive/MyDrive/Colab_Datasets/federated_models/densenet121_Consolidation_model.pth\n",
            "\n",
            "==================================================\n",
            "Training densenet121 for class: Edema\n",
            "==================================================\n",
            "\n",
            "Round 1/10\n",
            "Avg Train Loss: 0.6799, Avg Train Acc: 60.21%\n",
            "Avg Val Loss: 0.6971, Avg Val Acc: 51.25%\n",
            "F1 Score: 0.3473, AUC: 0.5579, MAP: 0.5575\n",
            "\n",
            "Round 2/10\n",
            "Avg Train Loss: 0.6101, Avg Train Acc: 67.06%\n",
            "Avg Val Loss: 0.7212, Avg Val Acc: 54.00%\n",
            "F1 Score: 0.4058, AUC: 0.6436, MAP: 0.6278\n",
            "\n",
            "Round 3/10\n",
            "Avg Train Loss: 0.5060, Avg Train Acc: 74.92%\n",
            "Avg Val Loss: 0.7110, Avg Val Acc: 57.75%\n",
            "F1 Score: 0.4961, AUC: 0.6578, MAP: 0.6438\n",
            "\n",
            "Round 4/10\n",
            "Avg Train Loss: 0.4342, Avg Train Acc: 80.11%\n",
            "Avg Val Loss: 0.8583, Avg Val Acc: 54.75%\n",
            "F1 Score: 0.4405, AUC: 0.6345, MAP: 0.6190\n",
            "\n",
            "Round 5/10\n",
            "Avg Train Loss: 0.3674, Avg Train Acc: 83.08%\n",
            "Avg Val Loss: 0.7179, Avg Val Acc: 59.25%\n",
            "F1 Score: 0.5576, AUC: 0.6568, MAP: 0.6680\n",
            "\n",
            "Round 6/10\n",
            "Avg Train Loss: 0.3141, Avg Train Acc: 86.44%\n",
            "Avg Val Loss: 0.7779, Avg Val Acc: 59.00%\n",
            "F1 Score: 0.5499, AUC: 0.6543, MAP: 0.6554\n",
            "\n",
            "Round 7/10\n",
            "Avg Train Loss: 0.2759, Avg Train Acc: 88.31%\n",
            "Avg Val Loss: 0.7788, Avg Val Acc: 57.75%\n",
            "F1 Score: 0.5370, AUC: 0.6467, MAP: 0.6493\n",
            "\n",
            "Round 8/10\n",
            "Avg Train Loss: 0.2673, Avg Train Acc: 88.64%\n",
            "Avg Val Loss: 0.9693, Avg Val Acc: 57.50%\n",
            "F1 Score: 0.5121, AUC: 0.6530, MAP: 0.6524\n",
            "\n",
            "Round 9/10\n",
            "Avg Train Loss: 0.2097, Avg Train Acc: 91.62%\n",
            "Avg Val Loss: 1.0699, Avg Val Acc: 58.00%\n",
            "F1 Score: 0.5159, AUC: 0.6438, MAP: 0.6349\n",
            "\n",
            "Round 10/10\n",
            "Avg Train Loss: 0.2047, Avg Train Acc: 91.65%\n",
            "Avg Val Loss: 1.0585, Avg Val Acc: 57.25%\n",
            "F1 Score: 0.4996, AUC: 0.6370, MAP: 0.6296\n",
            "\n",
            "Test Results:\n",
            "Test Loss: 1.0613\n",
            "Test Accuracy: 56.75%\n",
            "Test F1 Score: 0.4934\n",
            "Test AUC: 0.6134\n",
            "Test MAP: 0.5901\n",
            "Test Recall: 0.5675\n",
            "Model saved to /content/drive/MyDrive/Colab_Datasets/federated_models/densenet121_Edema_model.pth\n",
            "\n",
            "==================================================\n",
            "Training densenet121 for class: Pleural_Effusion\n",
            "==================================================\n",
            "\n",
            "Round 1/10\n",
            "Avg Train Loss: 0.7128, Avg Train Acc: 55.76%\n",
            "Avg Val Loss: 0.7066, Avg Val Acc: 48.75%\n",
            "F1 Score: 0.3195, AUC: 0.5448, MAP: 0.5271\n",
            "\n",
            "Round 2/10\n",
            "Avg Train Loss: 0.6530, Avg Train Acc: 62.21%\n",
            "Avg Val Loss: 0.6862, Avg Val Acc: 57.50%\n",
            "F1 Score: 0.5668, AUC: 0.5758, MAP: 0.5682\n",
            "\n",
            "Round 3/10\n",
            "Avg Train Loss: 0.5752, Avg Train Acc: 68.83%\n",
            "Avg Val Loss: 0.6811, Avg Val Acc: 54.25%\n",
            "F1 Score: 0.5418, AUC: 0.5936, MAP: 0.5811\n",
            "\n",
            "Round 4/10\n",
            "Avg Train Loss: 0.4844, Avg Train Acc: 76.53%\n",
            "Avg Val Loss: 0.8557, Avg Val Acc: 50.50%\n",
            "F1 Score: 0.4641, AUC: 0.6056, MAP: 0.5810\n",
            "\n",
            "Round 5/10\n",
            "Avg Train Loss: 0.3837, Avg Train Acc: 82.51%\n",
            "Avg Val Loss: 0.9487, Avg Val Acc: 56.00%\n",
            "F1 Score: 0.5324, AUC: 0.5885, MAP: 0.5869\n",
            "\n",
            "Round 6/10\n",
            "Avg Train Loss: 0.3457, Avg Train Acc: 84.55%\n",
            "Avg Val Loss: 0.7973, Avg Val Acc: 54.25%\n",
            "F1 Score: 0.5396, AUC: 0.5925, MAP: 0.6010\n",
            "\n",
            "Round 7/10\n",
            "Avg Train Loss: 0.3013, Avg Train Acc: 87.11%\n",
            "Avg Val Loss: 0.9523, Avg Val Acc: 58.25%\n",
            "F1 Score: 0.5669, AUC: 0.5956, MAP: 0.5991\n",
            "\n",
            "Round 8/10\n",
            "Avg Train Loss: 0.2778, Avg Train Acc: 88.11%\n",
            "Avg Val Loss: 1.0715, Avg Val Acc: 54.50%\n",
            "F1 Score: 0.4755, AUC: 0.5927, MAP: 0.6087\n",
            "\n",
            "Round 9/10\n",
            "Avg Train Loss: 0.2178, Avg Train Acc: 91.09%\n",
            "Avg Val Loss: 0.9476, Avg Val Acc: 57.25%\n",
            "F1 Score: 0.5725, AUC: 0.6045, MAP: 0.5880\n",
            "\n",
            "Round 10/10\n",
            "Avg Train Loss: 0.2005, Avg Train Acc: 92.10%\n",
            "Avg Val Loss: 1.0535, Avg Val Acc: 57.00%\n",
            "F1 Score: 0.5525, AUC: 0.6015, MAP: 0.5919\n",
            "\n",
            "Test Results:\n",
            "Test Loss: 1.1241\n",
            "Test Accuracy: 56.25%\n",
            "Test F1 Score: 0.5457\n",
            "Test AUC: 0.5775\n",
            "Test MAP: 0.5695\n",
            "Test Recall: 0.5625\n",
            "Model saved to /content/drive/MyDrive/Colab_Datasets/federated_models/densenet121_Pleural_Effusion_model.pth\n",
            "\n",
            "==================================================\n",
            "Training densenet121 for Multi-Class Classification\n",
            "==================================================\n",
            "\n",
            "Round 1/10\n",
            "Avg Train Loss: 1.6094, Avg Train Acc: 26.08%\n",
            "Avg Val Loss: 1.6130, Avg Val Acc: 20.40%\n",
            "F1 Score: 0.0691, AUC: 0.5805, MAP: 0.2488\n",
            "\n",
            "Round 2/10\n",
            "Avg Train Loss: 1.5752, Avg Train Acc: 28.47%\n",
            "Avg Val Loss: 1.6084, Avg Val Acc: 24.00%\n",
            "F1 Score: 0.1387, AUC: 0.6373, MAP: 0.3125\n",
            "\n",
            "Round 3/10\n",
            "Avg Train Loss: 1.5333, Avg Train Acc: 32.08%\n",
            "Avg Val Loss: 1.6061, Avg Val Acc: 24.20%\n",
            "F1 Score: 0.1693, AUC: 0.6505, MAP: 0.3343\n",
            "\n",
            "Round 4/10\n",
            "Avg Train Loss: 1.4486, Avg Train Acc: 37.48%\n",
            "Avg Val Loss: 1.5674, Avg Val Acc: 31.10%\n",
            "F1 Score: 0.2871, AUC: 0.6586, MAP: 0.3378\n",
            "\n",
            "Round 5/10\n",
            "Avg Train Loss: 1.3478, Avg Train Acc: 44.09%\n",
            "Avg Val Loss: 1.6177, Avg Val Acc: 32.60%\n",
            "F1 Score: 0.2919, AUC: 0.6637, MAP: 0.3455\n",
            "\n",
            "Round 6/10\n",
            "Avg Train Loss: 1.2290, Avg Train Acc: 50.27%\n",
            "Avg Val Loss: 1.7312, Avg Val Acc: 29.20%\n",
            "F1 Score: 0.2401, AUC: 0.6659, MAP: 0.3370\n",
            "\n",
            "Round 7/10\n",
            "Avg Train Loss: 1.0821, Avg Train Acc: 57.33%\n",
            "Avg Val Loss: 1.7504, Avg Val Acc: 32.00%\n",
            "F1 Score: 0.2837, AUC: 0.6599, MAP: 0.3359\n",
            "\n",
            "Round 8/10\n",
            "Avg Train Loss: 0.9205, Avg Train Acc: 64.75%\n",
            "Avg Val Loss: 2.0257, Avg Val Acc: 30.30%\n",
            "F1 Score: 0.2627, AUC: 0.6431, MAP: 0.3155\n",
            "\n",
            "Round 9/10\n",
            "Avg Train Loss: 0.8060, Avg Train Acc: 69.47%\n",
            "Avg Val Loss: 1.8241, Avg Val Acc: 32.00%\n",
            "F1 Score: 0.3044, AUC: 0.6492, MAP: 0.3231\n",
            "\n",
            "Round 10/10\n",
            "Avg Train Loss: 0.6375, Avg Train Acc: 76.22%\n",
            "Avg Val Loss: 2.3801, Avg Val Acc: 30.50%\n",
            "F1 Score: 0.2750, AUC: 0.6491, MAP: 0.3208\n",
            "\n",
            "Test Results:\n",
            "Test Loss: 2.3569\n",
            "Test Accuracy: 28.00%\n",
            "Test F1 Score: 0.2534\n",
            "Test AUC: 0.6356\n",
            "Test MAP: 0.3131\n",
            "Test Recall: 0.2800\n",
            "Model saved to /content/drive/MyDrive/Colab_Datasets/federated_models/densenet121_multiclass_model.pth\n",
            "\n",
            "==================================================\n",
            "Generating Visualizations for densenet121\n",
            "==================================================\n",
            "Visualizations saved to /content/drive/MyDrive/Colab_Datasets/federated_models/densenet121_figures\n",
            "\n",
            "\n",
            "############################################################\n",
            "TRAINING MODEL: EFFICIENTNET\n",
            "############################################################\n",
            "\n",
            "==================================================\n",
            "Training efficientnet for class: Atelectasis\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
            "100%|| 20.5M/20.5M [00:02<00:00, 8.13MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Round 1/10\n",
            "Avg Train Loss: 0.5346, Avg Train Acc: 71.45%\n",
            "Avg Val Loss: 0.6620, Avg Val Acc: 57.75%\n",
            "F1 Score: 0.5768, AUC: 0.6304, MAP: 0.6091\n",
            "\n",
            "Round 2/10\n",
            "Avg Train Loss: 0.3733, Avg Train Acc: 82.80%\n",
            "Avg Val Loss: 0.7215, Avg Val Acc: 61.50%\n",
            "F1 Score: 0.6153, AUC: 0.6626, MAP: 0.6153\n",
            "\n",
            "Round 3/10\n",
            "Avg Train Loss: 0.2707, Avg Train Acc: 88.19%\n",
            "Avg Val Loss: 0.8265, Avg Val Acc: 59.75%\n",
            "F1 Score: 0.5864, AUC: 0.6432, MAP: 0.6006\n",
            "\n",
            "Round 4/10\n",
            "Avg Train Loss: 0.2253, Avg Train Acc: 90.49%\n",
            "Avg Val Loss: 0.8371, Avg Val Acc: 60.75%\n",
            "F1 Score: 0.6058, AUC: 0.6542, MAP: 0.6184\n",
            "\n",
            "Round 5/10\n",
            "Avg Train Loss: 0.1828, Avg Train Acc: 92.70%\n",
            "Avg Val Loss: 1.0001, Avg Val Acc: 59.25%\n",
            "F1 Score: 0.5874, AUC: 0.6215, MAP: 0.5785\n",
            "\n",
            "Round 6/10\n",
            "Avg Train Loss: 0.1357, Avg Train Acc: 94.74%\n",
            "Avg Val Loss: 1.0613, Avg Val Acc: 60.50%\n",
            "F1 Score: 0.6046, AUC: 0.6372, MAP: 0.6080\n",
            "\n",
            "Round 7/10\n",
            "Avg Train Loss: 0.1267, Avg Train Acc: 95.33%\n",
            "Avg Val Loss: 1.0968, Avg Val Acc: 60.75%\n",
            "F1 Score: 0.6066, AUC: 0.6495, MAP: 0.5917\n",
            "\n",
            "Round 8/10\n",
            "Avg Train Loss: 0.1276, Avg Train Acc: 95.38%\n",
            "Avg Val Loss: 1.0841, Avg Val Acc: 60.00%\n",
            "F1 Score: 0.6006, AUC: 0.6411, MAP: 0.5791\n",
            "\n",
            "Round 9/10\n",
            "Avg Train Loss: 0.0946, Avg Train Acc: 96.41%\n",
            "Avg Val Loss: 1.2375, Avg Val Acc: 60.50%\n",
            "F1 Score: 0.6054, AUC: 0.6484, MAP: 0.5736\n",
            "\n",
            "Round 10/10\n",
            "Avg Train Loss: 0.0899, Avg Train Acc: 96.62%\n",
            "Avg Val Loss: 1.3029, Avg Val Acc: 58.50%\n",
            "F1 Score: 0.5854, AUC: 0.6457, MAP: 0.6095\n",
            "\n",
            "Test Results:\n",
            "Test Loss: 1.4661\n",
            "Test Accuracy: 58.00%\n",
            "Test F1 Score: 0.5800\n",
            "Test AUC: 0.6017\n",
            "Test MAP: 0.6095\n",
            "Test Recall: 0.5800\n",
            "Model saved to /content/drive/MyDrive/Colab_Datasets/federated_models/efficientnet_Atelectasis_model.pth\n",
            "\n",
            "==================================================\n",
            "Training efficientnet for class: Cardiomegaly\n",
            "==================================================\n",
            "\n",
            "Round 1/10\n",
            "Avg Train Loss: 0.5219, Avg Train Acc: 72.47%\n",
            "Avg Val Loss: 0.6767, Avg Val Acc: 59.00%\n",
            "F1 Score: 0.5883, AUC: 0.6138, MAP: 0.5999\n",
            "\n",
            "Round 2/10\n",
            "Avg Train Loss: 0.3419, Avg Train Acc: 84.92%\n",
            "Avg Val Loss: 0.8100, Avg Val Acc: 61.00%\n",
            "F1 Score: 0.6093, AUC: 0.6512, MAP: 0.6126\n",
            "\n",
            "Round 3/10\n",
            "Avg Train Loss: 0.2448, Avg Train Acc: 89.99%\n",
            "Avg Val Loss: 0.8133, Avg Val Acc: 63.50%\n",
            "F1 Score: 0.6317, AUC: 0.6773, MAP: 0.6263\n",
            "\n",
            "Round 4/10\n",
            "Avg Train Loss: 0.2043, Avg Train Acc: 91.99%\n",
            "Avg Val Loss: 0.8800, Avg Val Acc: 63.25%\n",
            "F1 Score: 0.6325, AUC: 0.6718, MAP: 0.6235\n",
            "\n",
            "Round 5/10\n",
            "Avg Train Loss: 0.1591, Avg Train Acc: 93.67%\n",
            "Avg Val Loss: 1.0735, Avg Val Acc: 61.00%\n",
            "F1 Score: 0.6081, AUC: 0.6670, MAP: 0.6470\n",
            "\n",
            "Round 6/10\n",
            "Avg Train Loss: 0.1381, Avg Train Acc: 94.78%\n",
            "Avg Val Loss: 1.1353, Avg Val Acc: 62.75%\n",
            "F1 Score: 0.6259, AUC: 0.6667, MAP: 0.6202\n",
            "\n",
            "Round 7/10\n",
            "Avg Train Loss: 0.1117, Avg Train Acc: 95.76%\n",
            "Avg Val Loss: 1.1814, Avg Val Acc: 63.25%\n",
            "F1 Score: 0.6327, AUC: 0.6802, MAP: 0.6511\n",
            "\n",
            "Round 8/10\n",
            "Avg Train Loss: 0.0945, Avg Train Acc: 96.45%\n",
            "Avg Val Loss: 1.4169, Avg Val Acc: 59.50%\n",
            "F1 Score: 0.5886, AUC: 0.6506, MAP: 0.6139\n",
            "\n",
            "Round 9/10\n",
            "Avg Train Loss: 0.0906, Avg Train Acc: 96.58%\n",
            "Avg Val Loss: 1.2851, Avg Val Acc: 60.25%\n",
            "F1 Score: 0.6023, AUC: 0.6636, MAP: 0.6455\n",
            "\n",
            "Round 10/10\n",
            "Avg Train Loss: 0.0942, Avg Train Acc: 96.62%\n",
            "Avg Val Loss: 1.2507, Avg Val Acc: 63.25%\n",
            "F1 Score: 0.6325, AUC: 0.6729, MAP: 0.6339\n",
            "\n",
            "Test Results:\n",
            "Test Loss: 1.1723\n",
            "Test Accuracy: 66.75%\n",
            "Test F1 Score: 0.6674\n",
            "Test AUC: 0.7179\n",
            "Test MAP: 0.6858\n",
            "Test Recall: 0.6675\n",
            "Model saved to /content/drive/MyDrive/Colab_Datasets/federated_models/efficientnet_Cardiomegaly_model.pth\n",
            "\n",
            "==================================================\n",
            "Training efficientnet for class: Consolidation\n",
            "==================================================\n",
            "\n",
            "Round 1/10\n",
            "Avg Train Loss: 0.5136, Avg Train Acc: 73.39%\n",
            "Avg Val Loss: 0.6723, Avg Val Acc: 56.50%\n",
            "F1 Score: 0.5612, AUC: 0.6156, MAP: 0.6205\n",
            "\n",
            "Round 2/10\n",
            "Avg Train Loss: 0.3497, Avg Train Acc: 84.39%\n",
            "Avg Val Loss: 0.7291, Avg Val Acc: 56.75%\n",
            "F1 Score: 0.5306, AUC: 0.6752, MAP: 0.6718\n",
            "\n",
            "Round 3/10\n",
            "Avg Train Loss: 0.2445, Avg Train Acc: 90.28%\n",
            "Avg Val Loss: 0.7841, Avg Val Acc: 60.00%\n",
            "F1 Score: 0.5961, AUC: 0.6437, MAP: 0.6491\n",
            "\n",
            "Round 4/10\n",
            "Avg Train Loss: 0.2069, Avg Train Acc: 92.09%\n",
            "Avg Val Loss: 0.7985, Avg Val Acc: 60.00%\n",
            "F1 Score: 0.5948, AUC: 0.6565, MAP: 0.6806\n",
            "\n",
            "Round 5/10\n",
            "Avg Train Loss: 0.1673, Avg Train Acc: 93.41%\n",
            "Avg Val Loss: 0.8774, Avg Val Acc: 62.50%\n",
            "F1 Score: 0.6233, AUC: 0.6675, MAP: 0.6759\n",
            "\n",
            "Round 6/10\n",
            "Avg Train Loss: 0.1329, Avg Train Acc: 94.71%\n",
            "Avg Val Loss: 0.9855, Avg Val Acc: 61.75%\n",
            "F1 Score: 0.6150, AUC: 0.6597, MAP: 0.6677\n",
            "\n",
            "Round 7/10\n",
            "Avg Train Loss: 0.1367, Avg Train Acc: 94.90%\n",
            "Avg Val Loss: 0.9333, Avg Val Acc: 60.25%\n",
            "F1 Score: 0.6006, AUC: 0.6478, MAP: 0.6790\n",
            "\n",
            "Round 8/10\n",
            "Avg Train Loss: 0.0900, Avg Train Acc: 96.80%\n",
            "Avg Val Loss: 1.0707, Avg Val Acc: 61.00%\n",
            "F1 Score: 0.6100, AUC: 0.6589, MAP: 0.6819\n",
            "\n",
            "Round 9/10\n",
            "Avg Train Loss: 0.1055, Avg Train Acc: 96.09%\n",
            "Avg Val Loss: 1.1437, Avg Val Acc: 58.75%\n",
            "F1 Score: 0.5845, AUC: 0.6278, MAP: 0.6478\n",
            "\n",
            "Round 10/10\n",
            "Avg Train Loss: 0.0742, Avg Train Acc: 97.21%\n",
            "Avg Val Loss: 1.2730, Avg Val Acc: 57.75%\n",
            "F1 Score: 0.5751, AUC: 0.6478, MAP: 0.6654\n",
            "\n",
            "Test Results:\n",
            "Test Loss: 1.2769\n",
            "Test Accuracy: 57.75%\n",
            "Test F1 Score: 0.5763\n",
            "Test AUC: 0.6150\n",
            "Test MAP: 0.6383\n",
            "Test Recall: 0.5775\n",
            "Model saved to /content/drive/MyDrive/Colab_Datasets/federated_models/efficientnet_Consolidation_model.pth\n",
            "\n",
            "==================================================\n",
            "Training efficientnet for class: Edema\n",
            "==================================================\n",
            "\n",
            "Round 1/10\n",
            "Avg Train Loss: 0.5149, Avg Train Acc: 73.03%\n",
            "Avg Val Loss: 0.6475, Avg Val Acc: 60.00%\n",
            "F1 Score: 0.6000, AUC: 0.6616, MAP: 0.6126\n",
            "\n",
            "Round 2/10\n",
            "Avg Train Loss: 0.3396, Avg Train Acc: 84.97%\n",
            "Avg Val Loss: 0.6539, Avg Val Acc: 62.50%\n",
            "F1 Score: 0.6240, AUC: 0.6872, MAP: 0.6276\n",
            "\n",
            "Round 3/10\n",
            "Avg Train Loss: 0.2590, Avg Train Acc: 88.97%\n",
            "Avg Val Loss: 0.7567, Avg Val Acc: 61.50%\n",
            "F1 Score: 0.6019, AUC: 0.6746, MAP: 0.6576\n",
            "\n",
            "Round 4/10\n",
            "Avg Train Loss: 0.2282, Avg Train Acc: 90.47%\n",
            "Avg Val Loss: 0.7271, Avg Val Acc: 63.75%\n",
            "F1 Score: 0.6375, AUC: 0.6802, MAP: 0.6380\n",
            "\n",
            "Round 5/10\n",
            "Avg Train Loss: 0.1664, Avg Train Acc: 93.39%\n",
            "Avg Val Loss: 0.8566, Avg Val Acc: 60.75%\n",
            "F1 Score: 0.6047, AUC: 0.6663, MAP: 0.6255\n",
            "\n",
            "Round 6/10\n",
            "Avg Train Loss: 0.1513, Avg Train Acc: 94.24%\n",
            "Avg Val Loss: 0.9127, Avg Val Acc: 62.00%\n",
            "F1 Score: 0.6152, AUC: 0.6754, MAP: 0.6242\n",
            "\n",
            "Round 7/10\n",
            "Avg Train Loss: 0.1225, Avg Train Acc: 95.33%\n",
            "Avg Val Loss: 0.9067, Avg Val Acc: 63.25%\n",
            "F1 Score: 0.6314, AUC: 0.6824, MAP: 0.6497\n",
            "\n",
            "Round 8/10\n",
            "Avg Train Loss: 0.1140, Avg Train Acc: 95.88%\n",
            "Avg Val Loss: 0.9401, Avg Val Acc: 61.50%\n",
            "F1 Score: 0.6136, AUC: 0.6917, MAP: 0.6489\n",
            "\n",
            "Round 9/10\n",
            "Avg Train Loss: 0.0975, Avg Train Acc: 96.36%\n",
            "Avg Val Loss: 1.0051, Avg Val Acc: 64.00%\n",
            "F1 Score: 0.6398, AUC: 0.6864, MAP: 0.6424\n",
            "\n",
            "Round 10/10\n",
            "Avg Train Loss: 0.0839, Avg Train Acc: 97.05%\n",
            "Avg Val Loss: 1.0875, Avg Val Acc: 61.75%\n",
            "F1 Score: 0.6168, AUC: 0.6598, MAP: 0.6173\n",
            "\n",
            "Test Results:\n",
            "Test Loss: 1.3079\n",
            "Test Accuracy: 54.00%\n",
            "Test F1 Score: 0.5362\n",
            "Test AUC: 0.5791\n",
            "Test MAP: 0.5759\n",
            "Test Recall: 0.5400\n",
            "Model saved to /content/drive/MyDrive/Colab_Datasets/federated_models/efficientnet_Edema_model.pth\n",
            "\n",
            "==================================================\n",
            "Training efficientnet for class: Pleural_Effusion\n",
            "==================================================\n",
            "\n",
            "Round 1/10\n",
            "Avg Train Loss: 0.5405, Avg Train Acc: 70.56%\n",
            "Avg Val Loss: 0.6940, Avg Val Acc: 54.50%\n",
            "F1 Score: 0.5254, AUC: 0.5787, MAP: 0.5814\n",
            "\n",
            "Round 2/10\n",
            "Avg Train Loss: 0.3575, Avg Train Acc: 83.69%\n",
            "Avg Val Loss: 0.7572, Avg Val Acc: 53.50%\n",
            "F1 Score: 0.5342, AUC: 0.5786, MAP: 0.6037\n",
            "\n",
            "Round 3/10\n",
            "Avg Train Loss: 0.2758, Avg Train Acc: 88.39%\n",
            "Avg Val Loss: 0.7903, Avg Val Acc: 57.75%\n",
            "F1 Score: 0.5763, AUC: 0.6020, MAP: 0.5838\n",
            "\n",
            "Round 4/10\n",
            "Avg Train Loss: 0.2171, Avg Train Acc: 90.97%\n",
            "Avg Val Loss: 0.8635, Avg Val Acc: 55.50%\n",
            "F1 Score: 0.5527, AUC: 0.5881, MAP: 0.6043\n",
            "\n",
            "Round 5/10\n",
            "Avg Train Loss: 0.1564, Avg Train Acc: 94.08%\n",
            "Avg Val Loss: 0.9896, Avg Val Acc: 56.50%\n",
            "F1 Score: 0.5646, AUC: 0.5662, MAP: 0.5600\n",
            "\n",
            "Round 6/10\n",
            "Avg Train Loss: 0.1581, Avg Train Acc: 93.95%\n",
            "Avg Val Loss: 1.0967, Avg Val Acc: 53.25%\n",
            "F1 Score: 0.5272, AUC: 0.5635, MAP: 0.5583\n",
            "\n",
            "Round 7/10\n",
            "Avg Train Loss: 0.1300, Avg Train Acc: 95.01%\n",
            "Avg Val Loss: 1.1030, Avg Val Acc: 56.00%\n",
            "F1 Score: 0.5602, AUC: 0.5864, MAP: 0.5718\n",
            "\n",
            "Round 8/10\n",
            "Avg Train Loss: 0.1198, Avg Train Acc: 95.38%\n",
            "Avg Val Loss: 1.2106, Avg Val Acc: 55.00%\n",
            "F1 Score: 0.5483, AUC: 0.5290, MAP: 0.5411\n",
            "\n",
            "Round 9/10\n",
            "Avg Train Loss: 0.0898, Avg Train Acc: 96.61%\n",
            "Avg Val Loss: 1.1596, Avg Val Acc: 57.00%\n",
            "F1 Score: 0.5686, AUC: 0.5864, MAP: 0.5783\n",
            "\n",
            "Round 10/10\n",
            "Avg Train Loss: 0.0964, Avg Train Acc: 96.39%\n",
            "Avg Val Loss: 1.1239, Avg Val Acc: 57.25%\n",
            "F1 Score: 0.5715, AUC: 0.6072, MAP: 0.6102\n",
            "\n",
            "Test Results:\n",
            "Test Loss: 1.3506\n",
            "Test Accuracy: 57.00%\n",
            "Test F1 Score: 0.5700\n",
            "Test AUC: 0.5931\n",
            "Test MAP: 0.5858\n",
            "Test Recall: 0.5700\n",
            "Model saved to /content/drive/MyDrive/Colab_Datasets/federated_models/efficientnet_Pleural_Effusion_model.pth\n",
            "\n",
            "==================================================\n",
            "Training efficientnet for Multi-Class Classification\n",
            "==================================================\n",
            "\n",
            "Round 1/10\n",
            "Avg Train Loss: 1.4113, Avg Train Acc: 38.76%\n",
            "Avg Val Loss: 1.5722, Avg Val Acc: 29.10%\n",
            "F1 Score: 0.2550, AUC: 0.6143, MAP: 0.2971\n",
            "\n",
            "Round 2/10\n",
            "Avg Train Loss: 1.0773, Avg Train Acc: 57.20%\n",
            "Avg Val Loss: 1.6486, Avg Val Acc: 32.90%\n",
            "F1 Score: 0.3076, AUC: 0.6488, MAP: 0.3259\n",
            "\n",
            "Round 3/10\n",
            "Avg Train Loss: 0.7629, Avg Train Acc: 71.19%\n",
            "Avg Val Loss: 1.8216, Avg Val Acc: 32.00%\n",
            "F1 Score: 0.2913, AUC: 0.6493, MAP: 0.3271\n",
            "\n",
            "Round 4/10\n",
            "Avg Train Loss: 0.5528, Avg Train Acc: 79.36%\n",
            "Avg Val Loss: 1.9648, Avg Val Acc: 31.40%\n",
            "F1 Score: 0.2999, AUC: 0.6404, MAP: 0.3168\n",
            "\n",
            "Round 5/10\n",
            "Avg Train Loss: 0.4644, Avg Train Acc: 82.94%\n",
            "Avg Val Loss: 2.0324, Avg Val Acc: 32.40%\n",
            "F1 Score: 0.3163, AUC: 0.6450, MAP: 0.3268\n",
            "\n",
            "Round 6/10\n",
            "Avg Train Loss: 0.3807, Avg Train Acc: 86.39%\n",
            "Avg Val Loss: 2.2657, Avg Val Acc: 30.80%\n",
            "F1 Score: 0.2991, AUC: 0.6313, MAP: 0.3090\n",
            "\n",
            "Round 7/10\n",
            "Avg Train Loss: 0.3215, Avg Train Acc: 88.28%\n",
            "Avg Val Loss: 2.3907, Avg Val Acc: 30.10%\n",
            "F1 Score: 0.2917, AUC: 0.6400, MAP: 0.3163\n",
            "\n",
            "Round 8/10\n",
            "Avg Train Loss: 0.2695, Avg Train Acc: 90.52%\n",
            "Avg Val Loss: 2.4669, Avg Val Acc: 31.70%\n",
            "F1 Score: 0.3010, AUC: 0.6408, MAP: 0.3134\n",
            "\n",
            "Round 9/10\n",
            "Avg Train Loss: 0.2210, Avg Train Acc: 92.31%\n",
            "Avg Val Loss: 2.7427, Avg Val Acc: 30.90%\n",
            "F1 Score: 0.2997, AUC: 0.6260, MAP: 0.3033\n",
            "\n",
            "Round 10/10\n",
            "Avg Train Loss: 0.2009, Avg Train Acc: 92.96%\n",
            "Avg Val Loss: 2.8173, Avg Val Acc: 31.20%\n",
            "F1 Score: 0.3068, AUC: 0.6319, MAP: 0.3018\n",
            "\n",
            "Test Results:\n",
            "Test Loss: 2.7318\n",
            "Test Accuracy: 33.00%\n",
            "Test F1 Score: 0.3243\n",
            "Test AUC: 0.6419\n",
            "Test MAP: 0.3129\n",
            "Test Recall: 0.3300\n",
            "Model saved to /content/drive/MyDrive/Colab_Datasets/federated_models/efficientnet_multiclass_model.pth\n",
            "\n",
            "==================================================\n",
            "Generating Visualizations for efficientnet\n",
            "==================================================\n",
            "Visualizations saved to /content/drive/MyDrive/Colab_Datasets/federated_models/efficientnet_figures\n",
            "\n",
            "============================================================\n",
            "FEDERATED LEARNING SUMMARY REPORT\n",
            "============================================================\n",
            "============================================================\n",
            "FEDERATED LEARNING EXPERIMENT RESULTS\n",
            "============================================================\n",
            "\n",
            "Experiment Configuration:\n",
            "  - Number of Clients: 5\n",
            "  - Number of Rounds: 10\n",
            "  - Local Epochs: 5\n",
            "  - Batch Size: 32\n",
            "  - Learning Rate: 0.001\n",
            "  - Samples per Class: 1000\n",
            "  - Device: cuda\n",
            "\n",
            "============================================================\n",
            "MODEL PERFORMANCE COMPARISON\n",
            "============================================================\n",
            "\n",
            "### Model: RESNET18 ###\n",
            "\n",
            "Per-Class Binary Classification Results:\n",
            "----------------------------------------\n",
            "\n",
            "  Atelectasis:\n",
            "    - Accuracy:  56.50%\n",
            "    - F1 Score:  0.5504\n",
            "    - AUC:       0.6134\n",
            "    - MAP:       0.6354\n",
            "    - Recall:    0.5650\n",
            "\n",
            "  Cardiomegaly:\n",
            "    - Accuracy:  66.50%\n",
            "    - F1 Score:  0.6650\n",
            "    - AUC:       0.7411\n",
            "    - MAP:       0.7490\n",
            "    - Recall:    0.6650\n",
            "\n",
            "  Consolidation:\n",
            "    - Accuracy:  58.50%\n",
            "    - F1 Score:  0.5726\n",
            "    - AUC:       0.6217\n",
            "    - MAP:       0.6286\n",
            "    - Recall:    0.5850\n",
            "\n",
            "  Edema:\n",
            "    - Accuracy:  59.50%\n",
            "    - F1 Score:  0.5900\n",
            "    - AUC:       0.6213\n",
            "    - MAP:       0.6135\n",
            "    - Recall:    0.5950\n",
            "\n",
            "  Pleural_Effusion:\n",
            "    - Accuracy:  57.25%\n",
            "    - F1 Score:  0.5623\n",
            "    - AUC:       0.6176\n",
            "    - MAP:       0.5866\n",
            "    - Recall:    0.5725\n",
            "\n",
            "  Multi-Class Classification Results:\n",
            "  --------------------------------------\n",
            "    - Accuracy:       34.00%\n",
            "    - F1 Score:       0.3375\n",
            "    - AUC:            0.6468\n",
            "    - MAP:            0.3176\n",
            "    - Recall:         0.3400\n",
            "    - Top-1 Accuracy: 34.00%\n",
            "    - Top-5 Accuracy: 100.00%\n",
            "\n",
            "### Model: DENSENET121 ###\n",
            "\n",
            "Per-Class Binary Classification Results:\n",
            "----------------------------------------\n",
            "\n",
            "  Atelectasis:\n",
            "    - Accuracy:  51.25%\n",
            "    - F1 Score:  0.3762\n",
            "    - AUC:       0.5815\n",
            "    - MAP:       0.5876\n",
            "    - Recall:    0.5125\n",
            "\n",
            "  Cardiomegaly:\n",
            "    - Accuracy:  66.75%\n",
            "    - F1 Score:  0.6672\n",
            "    - AUC:       0.7127\n",
            "    - MAP:       0.6978\n",
            "    - Recall:    0.6675\n",
            "\n",
            "  Consolidation:\n",
            "    - Accuracy:  57.75%\n",
            "    - F1 Score:  0.5499\n",
            "    - AUC:       0.6511\n",
            "    - MAP:       0.6561\n",
            "    - Recall:    0.5775\n",
            "\n",
            "  Edema:\n",
            "    - Accuracy:  56.75%\n",
            "    - F1 Score:  0.4934\n",
            "    - AUC:       0.6134\n",
            "    - MAP:       0.5901\n",
            "    - Recall:    0.5675\n",
            "\n",
            "  Pleural_Effusion:\n",
            "    - Accuracy:  56.25%\n",
            "    - F1 Score:  0.5457\n",
            "    - AUC:       0.5775\n",
            "    - MAP:       0.5695\n",
            "    - Recall:    0.5625\n",
            "\n",
            "  Multi-Class Classification Results:\n",
            "  --------------------------------------\n",
            "    - Accuracy:       28.00%\n",
            "    - F1 Score:       0.2534\n",
            "    - AUC:            0.6356\n",
            "    - MAP:            0.3131\n",
            "    - Recall:         0.2800\n",
            "    - Top-1 Accuracy: 28.00%\n",
            "    - Top-5 Accuracy: 100.00%\n",
            "\n",
            "### Model: EFFICIENTNET ###\n",
            "\n",
            "Per-Class Binary Classification Results:\n",
            "----------------------------------------\n",
            "\n",
            "  Atelectasis:\n",
            "    - Accuracy:  58.00%\n",
            "    - F1 Score:  0.5800\n",
            "    - AUC:       0.6017\n",
            "    - MAP:       0.6095\n",
            "    - Recall:    0.5800\n",
            "\n",
            "  Cardiomegaly:\n",
            "    - Accuracy:  66.75%\n",
            "    - F1 Score:  0.6674\n",
            "    - AUC:       0.7179\n",
            "    - MAP:       0.6858\n",
            "    - Recall:    0.6675\n",
            "\n",
            "  Consolidation:\n",
            "    - Accuracy:  57.75%\n",
            "    - F1 Score:  0.5763\n",
            "    - AUC:       0.6150\n",
            "    - MAP:       0.6383\n",
            "    - Recall:    0.5775\n",
            "\n",
            "  Edema:\n",
            "    - Accuracy:  54.00%\n",
            "    - F1 Score:  0.5362\n",
            "    - AUC:       0.5791\n",
            "    - MAP:       0.5759\n",
            "    - Recall:    0.5400\n",
            "\n",
            "  Pleural_Effusion:\n",
            "    - Accuracy:  57.00%\n",
            "    - F1 Score:  0.5700\n",
            "    - AUC:       0.5931\n",
            "    - MAP:       0.5858\n",
            "    - Recall:    0.5700\n",
            "\n",
            "  Multi-Class Classification Results:\n",
            "  --------------------------------------\n",
            "    - Accuracy:       33.00%\n",
            "    - F1 Score:       0.3243\n",
            "    - AUC:            0.6419\n",
            "    - MAP:            0.3129\n",
            "    - Recall:         0.3300\n",
            "    - Top-1 Accuracy: 33.00%\n",
            "    - Top-5 Accuracy: 100.00%\n",
            "\n",
            "============================================================\n",
            "BEST PERFORMING MODELS\n",
            "============================================================\n",
            "  ACCURACY: resnet18 (34.0000)\n",
            "  F1_SCORE: resnet18 (0.3375)\n",
            "  AUC: resnet18 (0.6468)\n",
            "  MAP: resnet18 (0.3176)\n",
            "  RECALL: resnet18 (0.3400)\n",
            "Results CSV saved to /content/drive/MyDrive/Colab_Datasets/federated_models/federated_results.csv\n",
            "\n",
            "Report saved to /content/drive/MyDrive/Colab_Datasets/federated_models/federated_learning_report.txt\n",
            "\n",
            "======================================================================\n",
            "FEDERATED LEARNING PIPELINE COMPLETED SUCCESSFULLY!\n",
            "======================================================================\n",
            "\n",
            "Pipeline execution completed!\n",
            "All models and results saved to: /content/drive/MyDrive/Colab_Datasets/federated_models\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Mount Google Drive first\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "    except:\n",
        "        print(\"Not running in Google Colab or Drive already mounted\")\n",
        "\n",
        "    # Install required packages if needed\n",
        "    import subprocess\n",
        "    import sys\n",
        "\n",
        "    def install_package(package):\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
        "\n",
        "    # Check and install required packages\n",
        "    required_packages = ['torch', 'torchvision', 'scikit-learn', 'matplotlib', 'seaborn', 'pandas', 'numpy']\n",
        "    for package in required_packages:\n",
        "        try:\n",
        "            __import__(package)\n",
        "        except ImportError:\n",
        "            print(f\"Installing {package}...\")\n",
        "            install_package(package)\n",
        "\n",
        "    # Run the pipeline\n",
        "    pipeline = main()\n",
        "\n",
        "    print(\"\\nPipeline execution completed!\")\n",
        "    print(f\"All models and results saved to: {Config.SAVE_DIR}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}