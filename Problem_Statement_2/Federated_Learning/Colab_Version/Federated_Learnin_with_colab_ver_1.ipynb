{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdca860d-ee35-448f-9801-54ceda9a44e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable GPU check\n",
    "import torch\n",
    "print(\"GPU Available:\", torch.cuda.is_available())\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eecf9b2-24d8-439e-82db-643da782bca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install missing libraries\n",
    "!pip install barbar tqdm scikit-learn pillow matplotlib pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e853ff-a055-49fc-b54d-f63c69e47393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8293109-dcf7-4798-9299-468e9fcd9eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Imports\n",
    "# =========================\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from barbar import Bar\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True\n",
    "\n",
    "# =========================\n",
    "# Logger\n",
    "# =========================\n",
    "def log(path, file):\n",
    "    log_file = os.path.join(path, file)\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    logging.basicConfig(level=logging.INFO, format=\"%(message)s\")\n",
    "    logger = logging.getLogger()\n",
    "\n",
    "    handler = logging.FileHandler(log_file)\n",
    "    handler.setLevel(logging.INFO)\n",
    "    handler.setFormatter(logging.Formatter(\"%(asctime)s: %(message)s\"))\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "# =========================\n",
    "# Config (Colab Version)\n",
    "# =========================\n",
    "class Config(object):\n",
    "    def __init__(self):\n",
    "        self.name = 'fed_chexpert_colab'\n",
    "\n",
    "        self.base_path = '/content/drive/MyDrive/chexpert'\n",
    "        self.save_path = f'{self.base_path}/ckpt'\n",
    "\n",
    "        self.train_csv = f'{self.base_path}/chexpert-train.csv'\n",
    "        self.valid_csv = f'{self.base_path}/chexpert-valid.csv'\n",
    "        self.test_csv  = f'{self.base_path}/chexpert-test.csv'\n",
    "\n",
    "        self.model_name = 'resnet18'\n",
    "        self.pre_train = True\n",
    "\n",
    "        self.img_size = 224\n",
    "        self.batch_size = 16\n",
    "        self.lr = 1e-4\n",
    "        self.num_classes = 14\n",
    "\n",
    "        self.num_workers = 2\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Federated Learning\n",
    "        self.num_clients = 5\n",
    "        self.client_epoch = 1\n",
    "        self.com_round = 3\n",
    "        self.fraction = 1.0\n",
    "\n",
    "        os.makedirs(self.save_path, exist_ok=True)\n",
    "        self.logger = log(self.save_path, f'{self.name}.log')\n",
    "\n",
    "opt = Config()\n",
    "opt.logger.info(\"Config Loaded\")\n",
    "\n",
    "# =========================\n",
    "# Dataset\n",
    "# =========================\n",
    "class CheXpertDataSet(Dataset):\n",
    "    def __init__(self, df, class_names, transform, policy=\"zeroes\"):\n",
    "        self.image_filepaths = df[\"Path\"].values\n",
    "        self.class_names = class_names\n",
    "        self.transform = transform\n",
    "\n",
    "        labels = []\n",
    "        for c in class_names:\n",
    "            labels.append(df[c].values)\n",
    "        self.labels = np.array(labels).T.astype(np.float32)\n",
    "\n",
    "        if policy == \"zeroes\":\n",
    "            self.labels[self.labels == -1] = 0\n",
    "        else:\n",
    "            self.labels[self.labels == -1] = 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(opt.base_path, self.image_filepaths[idx])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "# =========================\n",
    "# Transforms\n",
    "# =========================\n",
    "def get_transforms():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((opt.img_size, opt.img_size)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406], [0.229,0.224,0.225])\n",
    "    ])\n",
    "\n",
    "# =========================\n",
    "# Load Datasets\n",
    "# =========================\n",
    "def get_dataloaders():\n",
    "    train_df = pd.read_csv(opt.train_csv).fillna(-1)\n",
    "    valid_df = pd.read_csv(opt.valid_csv).fillna(-1)\n",
    "    test_df  = pd.read_csv(opt.test_csv).fillna(-1)\n",
    "\n",
    "    classes = [\n",
    "        'No Finding','Enlarged Cardiomediastinum','Cardiomegaly','Lung Opacity',\n",
    "        'Lung Lesion','Edema','Consolidation','Pneumonia','Atelectasis',\n",
    "        'Pneumothorax','Pleural Effusion','Pleural Other','Fracture','Support Devices'\n",
    "    ]\n",
    "\n",
    "    transform = get_transforms()\n",
    "\n",
    "    train_set = CheXpertDataSet(train_df, classes, transform)\n",
    "    val_set   = CheXpertDataSet(valid_df, classes, transform)\n",
    "    test_set  = CheXpertDataSet(test_df, classes, transform, policy=\"ones\")\n",
    "\n",
    "    # Small split for Colab\n",
    "    client_sets = random_split(train_set, [1000]*opt.num_clients)\n",
    "\n",
    "    train_loaders = [\n",
    "        DataLoader(cs, batch_size=opt.batch_size, shuffle=True,\n",
    "                   num_workers=opt.num_workers, pin_memory=True)\n",
    "        for cs in client_sets\n",
    "    ]\n",
    "\n",
    "    val_loader = DataLoader(val_set, batch_size=opt.batch_size)\n",
    "    test_loader = DataLoader(test_set, batch_size=1)\n",
    "\n",
    "    return client_sets, train_loaders, val_loader, test_loader\n",
    "\n",
    "# =========================\n",
    "# Model\n",
    "# =========================\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = torchvision.models.resnet18(pretrained=opt.pre_train)\n",
    "        in_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Linear(in_features, opt.num_classes),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# =========================\n",
    "# Metrics\n",
    "# =========================\n",
    "def compute_auroc(gt, pred):\n",
    "    gt = gt.cpu().numpy()\n",
    "    pred = pred.cpu().numpy()\n",
    "    scores = []\n",
    "    for i in range(opt.num_classes):\n",
    "        try:\n",
    "            scores.append(roc_auc_score(gt[:, i], pred[:, i]))\n",
    "        except:\n",
    "            pass\n",
    "    return np.mean(scores)\n",
    "\n",
    "# =========================\n",
    "# Train / Val\n",
    "# =========================\n",
    "def train_epoch(model, loader, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in Bar(loader):\n",
    "        x, y = x.to(opt.device), y.to(opt.device)\n",
    "        out = model(x)\n",
    "        loss = loss_fn(out, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def validate(model, loader, loss_fn):\n",
    "    model.eval()\n",
    "    gt, pred = [], []\n",
    "    loss_total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(opt.device), y.to(opt.device)\n",
    "            out = model(x)\n",
    "            loss_total += loss_fn(out, y).item()\n",
    "            gt.append(y)\n",
    "            pred.append(out)\n",
    "    gt = torch.cat(gt)\n",
    "    pred = torch.cat(pred)\n",
    "    return loss_total / len(loader), compute_auroc(gt, pred)\n",
    "\n",
    "# =========================\n",
    "# Federated Training\n",
    "# =========================\n",
    "def main():\n",
    "    client_sets, train_loaders, val_loader, _ = get_dataloaders()\n",
    "    loss_fn = nn.BCELoss()\n",
    "\n",
    "    global_model = Classifier().to(opt.device)\n",
    "    client_models = [Classifier().to(opt.device) for _ in range(opt.num_clients)]\n",
    "\n",
    "    for rnd in range(opt.com_round):\n",
    "        opt.logger.info(f\"\\n===== ROUND {rnd+1} =====\")\n",
    "        client_weights = []\n",
    "\n",
    "        for i in range(opt.num_clients):\n",
    "            client_models[i].load_state_dict(global_model.state_dict())\n",
    "            optimizer = optim.Adam(client_models[i].parameters(), lr=opt.lr)\n",
    "\n",
    "            train_epoch(client_models[i], train_loaders[i], optimizer, loss_fn)\n",
    "            client_weights.append(client_models[i].state_dict())\n",
    "\n",
    "        # FedAvg\n",
    "        new_state = {}\n",
    "        for k in global_model.state_dict().keys():\n",
    "            new_state[k] = sum(w[k] for w in client_weights) / len(client_weights)\n",
    "\n",
    "        global_model.load_state_dict(new_state)\n",
    "\n",
    "        val_loss, val_auc = validate(global_model, val_loader, loss_fn)\n",
    "        opt.logger.info(f\"Validation Loss: {val_loss:.4f}, AUROC: {val_auc:.4f}\")\n",
    "\n",
    "    torch.save(global_model.state_dict(), f\"{opt.save_path}/global_model.pth\")\n",
    "    opt.logger.info(\"Training Complete\")\n",
    "\n",
    "# =========================\n",
    "# Run\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
