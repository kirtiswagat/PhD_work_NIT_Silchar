{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de8aedf-0b67-4a75-80f8-202bd3d7f921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Imports\n",
    "# ============================================================\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve, auc, confusion_matrix\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# Configuration\n",
    "# ============================================================\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.base_path = \"/workspace/DATASETS/CheXpert-v1.0-small\"\n",
    "        self.train_csv = f\"{self.base_path}/chexpert-train.csv\"\n",
    "        self.valid_csv = f\"{self.base_path}/chexpert-valid.csv\"\n",
    "\n",
    "        self.save_path = \"./ckpt/fed_chexpert_visual\"\n",
    "        os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "        self.batch_size = 32\n",
    "        self.img_size = 224\n",
    "        self.lr = 1e-4\n",
    "        self.num_classes = 14\n",
    "\n",
    "        self.num_clients = 5\n",
    "        self.client_epoch = 2\n",
    "        self.rounds = 5\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "opt = Config()\n",
    "\n",
    "CLASS_NAMES = [\n",
    "    'No Finding','Enlarged Cardiomediastinum','Cardiomegaly','Lung Opacity',\n",
    "    'Lung Lesion','Edema','Consolidation','Pneumonia','Atelectasis',\n",
    "    'Pneumothorax','Pleural Effusion','Pleural Other','Fracture','Support Devices'\n",
    "]\n",
    "\n",
    "# ============================================================\n",
    "# Dataset\n",
    "# ============================================================\n",
    "class CheXpertDataset(Dataset):\n",
    "    def __init__(self, df, transform):\n",
    "        self.paths = df[\"Path\"].values\n",
    "        self.labels = df[CLASS_NAMES].values.astype(np.float32)\n",
    "        self.labels[self.labels == -1] = 0\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(os.path.join(opt.base_path, self.paths[idx])).convert(\"RGB\")\n",
    "        return self.transform(img), self.labels[idx]\n",
    "\n",
    "# ============================================================\n",
    "# Data Loaders\n",
    "# ============================================================\n",
    "def get_dataloaders():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((opt.img_size, opt.img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "    ])\n",
    "\n",
    "    train_df = pd.read_csv(opt.train_csv).fillna(-1)\n",
    "    val_df   = pd.read_csv(opt.valid_csv).fillna(-1)\n",
    "\n",
    "    train_set = CheXpertDataset(train_df, transform)\n",
    "    val_set   = CheXpertDataset(val_df, transform)\n",
    "\n",
    "    client_sets = random_split(\n",
    "        train_set,\n",
    "        [len(train_set)//opt.num_clients] * opt.num_clients\n",
    "    )\n",
    "\n",
    "    train_loaders = [\n",
    "        DataLoader(cs, batch_size=opt.batch_size, shuffle=True)\n",
    "        for cs in client_sets\n",
    "    ]\n",
    "\n",
    "    val_loader = DataLoader(val_set, batch_size=opt.batch_size)\n",
    "\n",
    "    return train_loaders, val_loader\n",
    "\n",
    "# ============================================================\n",
    "# Model\n",
    "# ============================================================\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = torchvision.models.resnet18(pretrained=True)\n",
    "        self.net.fc = nn.Sequential(\n",
    "            nn.Linear(self.net.fc.in_features, opt.num_classes),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# ============================================================\n",
    "# Training (Client-side)\n",
    "# ============================================================\n",
    "def train_client(model, loader):\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=opt.lr)\n",
    "    loss_fn = nn.BCELoss()\n",
    "\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "\n",
    "    for _ in range(opt.client_epoch):\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(opt.device), y.to(opt.device)\n",
    "            out = model(x)\n",
    "            loss = loss_fn(out, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            correct += ((out >= 0.5) == y).sum().item()\n",
    "            total += y.numel()\n",
    "\n",
    "    return total_loss / len(loader), correct / total\n",
    "\n",
    "# ============================================================\n",
    "# Metrics & Visualization Helpers\n",
    "# ============================================================\n",
    "def tune_thresholds(gt, pred):\n",
    "    thresholds = []\n",
    "    for c in range(opt.num_classes):\n",
    "        best_f1, best_t = 0, 0.5\n",
    "        for t in np.linspace(0.1, 0.9, 50):\n",
    "            f1 = f1_score(gt[:,c], (pred[:,c] >= t), zero_division=0)\n",
    "            if f1 > best_f1:\n",
    "                best_f1, best_t = f1, t\n",
    "        thresholds.append(best_t)\n",
    "    return thresholds\n",
    "\n",
    "def plot_training_curves(history):\n",
    "    r = history[\"round\"]\n",
    "    plt.figure(figsize=(12,4))\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(r, history[\"train_loss\"], label=\"Train Loss\")\n",
    "    plt.plot(r, history[\"val_loss\"], label=\"Val Loss\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Loss vs Round\")\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(r, history[\"train_acc\"], label=\"Train Acc\")\n",
    "    plt.plot(r, history[\"val_acc\"], label=\"Val Acc\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Accuracy vs Round\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_auc_roc(gt, pred):\n",
    "    plt.figure(figsize=(7,6))\n",
    "    for i, cname in enumerate(CLASS_NAMES):\n",
    "        fpr, tpr, _ = roc_curve(gt[:,i], pred[:,i])\n",
    "        auc_score = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f\"{cname} ({auc_score:.2f})\")\n",
    "    plt.plot([0,1],[0,1],'k--')\n",
    "    plt.legend(fontsize=6)\n",
    "    plt.title(\"AUC-ROC Curves\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrices(confusion):\n",
    "    for cname, cm in confusion.items():\n",
    "        mat = np.array([[cm[\"TN\"], cm[\"FP\"]],\n",
    "                        [cm[\"FN\"], cm[\"TP\"]]])\n",
    "        plt.figure(figsize=(3,3))\n",
    "        sns.heatmap(mat, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                    xticklabels=[\"Pred 0\",\"Pred 1\"],\n",
    "                    yticklabels=[\"True 0\",\"True 1\"])\n",
    "        plt.title(cname)\n",
    "        plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# MAIN\n",
    "# ============================================================\n",
    "def main():\n",
    "    train_loaders, val_loader = get_dataloaders()\n",
    "\n",
    "    global_model = Model().to(opt.device)\n",
    "    clients = [Model().to(opt.device) for _ in range(opt.num_clients)]\n",
    "\n",
    "    history = {\n",
    "        \"round\": [], \"train_loss\": [], \"train_acc\": [],\n",
    "        \"val_loss\": [], \"val_acc\": [], \"val_auc\": []\n",
    "    }\n",
    "\n",
    "    for rnd in range(opt.rounds):\n",
    "        print(f\"\\n===== ROUND {rnd+1} =====\")\n",
    "\n",
    "        client_states, losses, accs = [], [], []\n",
    "\n",
    "        # ---------- Client Training ----------\n",
    "        for i in range(opt.num_clients):\n",
    "            clients[i].load_state_dict(global_model.state_dict())\n",
    "            loss, acc = train_client(clients[i], train_loaders[i])\n",
    "            losses.append(loss)\n",
    "            accs.append(acc)\n",
    "            client_states.append(clients[i].state_dict())\n",
    "\n",
    "        # ---------- FedAvg ----------\n",
    "        new_state = {}\n",
    "        for k in global_model.state_dict():\n",
    "            new_state[k] = sum(cs[k] for cs in client_states) / opt.num_clients\n",
    "        global_model.load_state_dict(new_state)\n",
    "\n",
    "        # ---------- Validation ----------\n",
    "        global_model.eval()\n",
    "        GT, PRED = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                out = global_model(x.to(opt.device))\n",
    "                GT.append(y.numpy())\n",
    "                PRED.append(out.cpu().numpy())\n",
    "\n",
    "        GT = np.vstack(GT)\n",
    "        PRED = np.vstack(PRED)\n",
    "\n",
    "        thresholds = tune_thresholds(GT, PRED)\n",
    "        pred_bin = (PRED >= thresholds).astype(int)\n",
    "\n",
    "        val_acc = accuracy_score(GT, pred_bin)\n",
    "        val_auc = np.mean([\n",
    "            roc_auc_score(GT[:,i], PRED[:,i])\n",
    "            for i in range(opt.num_classes)\n",
    "        ])\n",
    "\n",
    "        confusion = {}\n",
    "        for i, cname in enumerate(CLASS_NAMES):\n",
    "            tn, fp, fn, tp = confusion_matrix(GT[:,i], pred_bin[:,i]).ravel()\n",
    "            confusion[cname] = {\"TP\":tp,\"FP\":fp,\"FN\":fn,\"TN\":tn}\n",
    "\n",
    "        history[\"round\"].append(rnd+1)\n",
    "        history[\"train_loss\"].append(np.mean(losses))\n",
    "        history[\"train_acc\"].append(np.mean(accs))\n",
    "        history[\"val_loss\"].append(1 - val_acc)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "        history[\"val_auc\"].append(val_auc)\n",
    "\n",
    "        print(f\"Val Acc: {val_acc:.4f}, Val AUC: {val_auc:.4f}\")\n",
    "\n",
    "    # ---------- Visualizations ----------\n",
    "    plot_training_curves(history)\n",
    "    plot_auc_roc(GT, PRED)\n",
    "    plot_confusion_matrices(confusion)\n",
    "\n",
    "    print(\"\\nâœ… Training + Visualization Completed\")\n",
    "\n",
    "# ============================================================\n",
    "# Entry Point\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
